# Few-Shot ì˜ˆì‹œ ë°ì´í„° ìˆ˜ì§‘ ì „ëµ

**ë¬¸ì œ**: Phase 1 êµ¬í˜„ì— ìˆ˜ë°± ê°œì˜ ì˜ˆì‹œê°€ í•„ìš”í•˜ì§€ë§Œ, ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ê¸°ì—ëŠ” í•œê³„ê°€ ìˆìŒ

**í•´ê²°ì±…**: ìë™í™”ëœ ë°ì´í„° ìˆ˜ì§‘ ë° ìƒì„± ë°©ë²• í™œìš©

---

## ë°©ë²• 1: LLMì„ í™œìš©í•œ Synthetic ë°ì´í„° ìƒì„± (â­ ì¶”ì²œ)

### ì¥ì 
- âœ… **ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥** (ê¸°ì¡´ LLM í™œìš©)
- âœ… **ì‚¬ìš©ì ë¶€ë‹´ ì—†ìŒ** (ìë™ ìƒì„±)
- âœ… **ë‹¤ì–‘ì„± í™•ë³´** (ì—¬ëŸ¬ íŒ¨í„´, ì–¸ì–´)
- âœ… **ë¹„ìš© íš¨ìœ¨ì ** (í•œ ë²ˆë§Œ ìƒì„±)

### êµ¬í˜„ ë°©ë²•

```python
# backend/scripts/generate_few_shot_examples.py

import asyncio
import json
from typing import List, Dict
from pathlib import Path

from core.llm_client import LLMClient

class FewShotExampleGenerator:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ intent classification ì˜ˆì‹œ ìë™ ìƒì„±"""

    def __init__(self):
        self.llm = LLMClient()
        self.output_file = Path("data/few_shot_examples.json")

    async def generate_examples(
        self,
        intent_category: str,
        count: int = 50,
        languages: List[str] = ["korean", "english"]
    ) -> List[Dict]:
        """íŠ¹ì • intentì— ëŒ€í•œ ì˜ˆì‹œ ìƒì„±

        Args:
            intent_category: "simple_conversation", "capability_question", etc.
            count: ìƒì„±í•  ì˜ˆì‹œ ê°œìˆ˜
            languages: ìƒì„±í•  ì–¸ì–´ ëª©ë¡

        Returns:
            List of {"input": "...", "intent": "...", "language": "..."}
        """

        prompt = self._build_generation_prompt(intent_category, count, languages)

        response = await self.llm.generate_async(
            prompt=prompt,
            temperature=0.8,  # ë‹¤ì–‘ì„±ì„ ìœ„í•´ ë†’ì€ temperature
            max_tokens=2000
        )

        # Parse LLM response
        examples = self._parse_llm_response(response)

        return examples

    def _build_generation_prompt(
        self,
        intent_category: str,
        count: int,
        languages: List[str]
    ) -> str:
        """ì˜ˆì‹œ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        # Intentë³„ ê°€ì´ë“œë¼ì¸
        guidelines = {
            "simple_conversation": """
Greetings, thanks, acknowledgments that should be answered directly without creating workflows.
Examples:
- "ì•ˆë…•í•˜ì„¸ìš”"
- "Hello"
- "ê°ì‚¬í•©ë‹ˆë‹¤"
- "Thank you"
            """,
            "capability_question": """
Questions asking WHETHER the system CAN do something, not asking it TO DO it.
Examples:
- "ê³„íšë„ ì‘ì„± ê°€ëŠ¥í•©ë‹ˆê¹Œ?" (Can you write plans?)
- "ì½”ë“œ ë¦¬ë·° í•  ìˆ˜ ìˆì–´?" (Can you do code review?)
- "Are you able to debug?"
- "Do you support testing?"
            """,
            "simple_question": """
Questions seeking information or explanation, not asking for code generation.
Examples:
- "Pythonì´ ë­ì•¼?" (What is Python?)
- "REST API ì„¤ëª…í•´ì¤˜" (Explain REST API)
- "What is Docker?"
- "Tell me about microservices"
            """,
            "coding_task": """
Actual requests to CREATE, MODIFY, or REVIEW code.
Examples:
- "REST APIë¥¼ ë§Œë“¤ì–´ì¤˜" (Create a REST API)
- "ì´ ì½”ë“œ ë¦¬ë·°í•´ì¤˜" (Review this code)
- "Write a Flask server"
- "Fix this bug"
            """,
            "complex_task": """
Large-scale projects or planning requests.
Examples:
- "ì „ì²´ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•í•´ì¤˜" (Build a full web app)
- "í”„ë¡œì íŠ¸ ê³„íšì„ ì‘ì„±í•´ì¤˜" (Write a project plan)
- "Design a microservices architecture"
- "Create a complete e-commerce system"
            """
        }

        guideline = guidelines.get(intent_category, "")
        lang_str = ", ".join(languages)

        return f"""Generate {count} diverse examples of user inputs that should be classified as "{intent_category}".

**Guidelines:**
{guideline}

**Requirements:**
1. Generate examples in these languages: {lang_str}
2. Make them DIVERSE (different lengths, styles, formality levels)
3. Include edge cases and boundary examples
4. For each language, distribute examples evenly

**Output Format (JSON):**
[
  {{"input": "ì•ˆë…•í•˜ì„¸ìš”", "intent": "{intent_category}", "language": "korean"}},
  {{"input": "Hello", "intent": "{intent_category}", "language": "english"}},
  ...
]

Generate ONLY the JSON array, no additional text."""

    def _parse_llm_response(self, response: str) -> List[Dict]:
        """LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹±"""
        try:
            # Extract JSON from response (may have markdown code blocks)
            json_start = response.find('[')
            json_end = response.rfind(']') + 1

            if json_start == -1 or json_end == 0:
                raise ValueError("No JSON array found in response")

            json_str = response[json_start:json_end]
            examples = json.loads(json_str)

            return examples

        except Exception as e:
            print(f"Failed to parse LLM response: {e}")
            print(f"Response: {response[:500]}")
            return []

    async def generate_all_categories(self) -> Dict[str, List[Dict]]:
        """ëª¨ë“  intent categoryì— ëŒ€í•œ ì˜ˆì‹œ ìƒì„±"""

        categories = [
            "simple_conversation",
            "capability_question",
            "simple_question",
            "coding_task",
            "complex_task"
        ]

        all_examples = {}

        for category in categories:
            print(f"Generating examples for: {category}...")
            examples = await self.generate_examples(
                intent_category=category,
                count=50,  # ê° ì¹´í…Œê³ ë¦¬ë‹¹ 50ê°œ
                languages=["korean", "english"]
            )
            all_examples[category] = examples
            print(f"  Generated {len(examples)} examples")

        # Save to file
        self.output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(all_examples, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… Saved all examples to: {self.output_file}")
        print(f"   Total examples: {sum(len(v) for v in all_examples.values())}")

        return all_examples


async def main():
    """Generate few-shot examples"""
    generator = FewShotExampleGenerator()

    # Generate examples for all categories
    examples = await generator.generate_all_categories()

    # Print summary
    print("\nğŸ“Š Summary:")
    for category, items in examples.items():
        print(f"   {category}: {len(items)} examples")
        # Show first example
        if items:
            print(f"      Example: {items[0]['input']}")


if __name__ == "__main__":
    asyncio.run(main())
```

### ì‹¤í–‰ ë°©ë²•

```bash
# 1. ì˜ˆì‹œ ìƒì„± (í•œ ë²ˆë§Œ)
cd backend
python scripts/generate_few_shot_examples.py

# ì¶œë ¥ ì˜ˆì‹œ:
# Generating examples for: simple_conversation...
#   Generated 50 examples
# Generating examples for: capability_question...
#   Generated 50 examples
# ...
# âœ… Saved all examples to: data/few_shot_examples.json
#    Total examples: 250

# 2. Supervisorì—ì„œ ë¡œë“œ
# backend/core/supervisor.pyì—ì„œ ìë™ ë¡œë“œ
```

### ìƒì„± í’ˆì§ˆ ê²€ì¦

```python
# backend/scripts/validate_examples.py

import json
from pathlib import Path
from core.supervisor import SupervisorAgent

def validate_generated_examples():
    """ìƒì„±ëœ ì˜ˆì‹œì˜ í’ˆì§ˆ ê²€ì¦"""

    # Load generated examples
    examples_file = Path("data/few_shot_examples.json")
    with open(examples_file, 'r', encoding='utf-8') as f:
        all_examples = json.load(f)

    supervisor = SupervisorAgent()

    total = 0
    correct = 0

    for expected_intent, examples in all_examples.items():
        for example in examples:
            user_input = example['input']

            # Classify with supervisor
            analysis = supervisor.analyze_request(user_input)
            predicted_intent = analysis.get('intent')

            total += 1
            if predicted_intent == expected_intent:
                correct += 1
            else:
                print(f"âŒ MISMATCH:")
                print(f"   Input: {user_input}")
                print(f"   Expected: {expected_intent}")
                print(f"   Predicted: {predicted_intent}")

    accuracy = correct / total * 100
    print(f"\nâœ… Validation Result: {correct}/{total} ({accuracy:.1f}%)")

    return accuracy

if __name__ == "__main__":
    validate_generated_examples()
```

---

## ë°©ë²• 2: í˜„ì¬ ì‹œìŠ¤í…œ ë¡œê·¸ ë¶„ì„ (ì ì§„ì  ìˆ˜ì§‘)

### ì¥ì 
- âœ… **ì‹¤ì œ ì‚¬ìš©ì ì…ë ¥** (realistic data)
- âœ… **ìë™ ìˆ˜ì§‘** (ì‚¬ìš©ì í–‰ë™ ê¸°ë°˜)
- âœ… **ë¬´ë£Œ** (ì´ë¯¸ ìˆëŠ” ë°ì´í„°)

### êµ¬í˜„ ë°©ë²•

```python
# backend/scripts/collect_from_logs.py

import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict

from app.db import get_db
from app.db.repository import ConversationRepository

class LogBasedExampleCollector:
    """ì‹¤ì œ ì‚¬ìš© ë¡œê·¸ì—ì„œ ì˜ˆì‹œ ìˆ˜ì§‘"""

    def __init__(self):
        self.db = next(get_db())
        self.repo = ConversationRepository(self.db)

    def collect_examples(
        self,
        days: int = 30,
        min_confidence: float = 0.8
    ) -> Dict[str, List[Dict]]:
        """ìµœê·¼ Nì¼ê°„ì˜ ë¡œê·¸ì—ì„œ ì˜ˆì‹œ ìˆ˜ì§‘

        Args:
            days: ìˆ˜ì§‘ ê¸°ê°„
            min_confidence: ìµœì†Œ confidence (ë†’ì„ìˆ˜ë¡ ì •í™•í•œ ì˜ˆì‹œ)

        Returns:
            Dict of {intent: [examples]}
        """

        # Get recent conversations
        since = datetime.now() - timedelta(days=days)
        conversations = self.repo.list_conversations(limit=1000)

        examples_by_intent = {}

        for conv in conversations:
            if conv.created_at < since:
                continue

            # Get messages with metadata
            messages = self.repo.get_messages(conv.session_id)

            for msg in messages:
                if msg.role != 'user':
                    continue

                # Check if we have intent classification metadata
                meta = msg.meta_info or {}
                intent = meta.get('intent')
                confidence = meta.get('confidence_score', 0)

                if not intent or confidence < min_confidence:
                    continue

                # Add to examples
                if intent not in examples_by_intent:
                    examples_by_intent[intent] = []

                examples_by_intent[intent].append({
                    'input': msg.content,
                    'intent': intent,
                    'confidence': confidence,
                    'timestamp': msg.created_at.isoformat()
                })

        # Remove duplicates and sort by confidence
        for intent in examples_by_intent:
            # Deduplicate
            seen = set()
            unique = []
            for ex in examples_by_intent[intent]:
                if ex['input'] not in seen:
                    seen.add(ex['input'])
                    unique.append(ex)

            # Sort by confidence
            unique.sort(key=lambda x: x['confidence'], reverse=True)

            # Keep top 100
            examples_by_intent[intent] = unique[:100]

        return examples_by_intent

    def save_examples(self, examples: Dict, output_file: str = "data/log_based_examples.json"):
        """Save collected examples"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(examples, f, ensure_ascii=False, indent=2)

        print(f"âœ… Saved {sum(len(v) for v in examples.values())} examples to {output_path}")

def main():
    collector = LogBasedExampleCollector()

    # Collect from last 30 days
    examples = collector.collect_examples(days=30, min_confidence=0.8)

    # Print summary
    print("ğŸ“Š Collected Examples:")
    for intent, items in examples.items():
        print(f"   {intent}: {len(items)} examples")

    # Save
    collector.save_examples(examples)

if __name__ == "__main__":
    main()
```

---

## ë°©ë²• 3: ê³µê°œ ë°ì´í„°ì…‹ í™œìš© + ë²ˆì—­

### ë°ì´í„°ì…‹ ì†ŒìŠ¤
1. **ATIS (Airline Travel Information System)** - Intent classification benchmark
2. **SNIPS** - Intent detection dataset (7 intents)
3. **Banking77** - Banking domain intents
4. **HWU64** - 64 intents across 21 domains

### êµ¬í˜„ ë°©ë²•

```python
# backend/scripts/import_public_datasets.py

import requests
import json
from typing import List, Dict

class PublicDatasetImporter:
    """ê³µê°œ ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸°"""

    # Intent mapping (public dataset â†’ our intents)
    INTENT_MAPPING = {
        # SNIPS intents
        "GetWeather": "simple_question",
        "BookRestaurant": "coding_task",
        "PlayMusic": "coding_task",
        "AddToPlaylist": "coding_task",
        "RateBook": "simple_question",
        "SearchScreeningEvent": "simple_question",
        "SearchCreativeWork": "simple_question",

        # Banking77 examples
        "balance": "simple_question",
        "transfer": "coding_task",
        "card_issues": "simple_question",
        # ... (map all 77 intents)
    }

    def download_snips_dataset(self) -> List[Dict]:
        """Download SNIPS dataset"""
        # SNIPS is available on GitHub
        url = "https://github.com/snipsco/nlu-benchmark/raw/master/2017-06-custom-intent-engines/..."

        # ... (download and parse)
        pass

    def translate_to_korean(self, text: str) -> str:
        """ì˜ì–´ ì˜ˆì‹œë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
        # Use translation API or LLM
        # For now, use LLM
        prompt = f"Translate this to natural Korean:\n{text}\n\nKorean:"
        # ... call LLM
        pass
```

---

## ë°©ë²• 4: ì ì§„ì  ìˆ˜ì§‘ (Incremental Collection)

### ìë™ ì˜ˆì‹œ ìˆ˜ì§‘ ì‹œìŠ¤í…œ

```python
# backend/core/example_collector.py

from typing import Dict
from datetime import datetime
import json
from pathlib import Path

class IncrementalExampleCollector:
    """ì‚¬ìš©ì ì‚¬ìš© ì¤‘ ìë™ìœ¼ë¡œ ì˜ˆì‹œ ìˆ˜ì§‘"""

    def __init__(self, output_file: str = "data/incremental_examples.jsonl"):
        self.output_file = Path(output_file)
        self.output_file.parent.mkdir(parents=True, exist_ok=True)

    def record_classification(
        self,
        user_input: str,
        predicted_intent: str,
        confidence: float,
        was_correct: bool = None  # User feedbackìœ¼ë¡œ í™•ì¸
    ):
        """ë¶„ë¥˜ ê²°ê³¼ ê¸°ë¡"""

        # Only record high-confidence classifications
        if confidence < 0.85:
            return

        record = {
            'timestamp': datetime.utcnow().isoformat(),
            'input': user_input,
            'intent': predicted_intent,
            'confidence': confidence,
            'verified': was_correct
        }

        # Append to JSONL file
        with open(self.output_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(record, ensure_ascii=False) + '\n')

    def get_collected_examples(self, min_count: int = 100) -> Dict:
        """ìˆ˜ì§‘ëœ ì˜ˆì‹œë¥¼ few-shot formatìœ¼ë¡œ ë³€í™˜"""

        if not self.output_file.exists():
            return {}

        examples_by_intent = {}

        with open(self.output_file, 'r', encoding='utf-8') as f:
            for line in f:
                record = json.loads(line)

                # Skip unverified low-confidence
                if record.get('verified') is False:
                    continue

                intent = record['intent']
                if intent not in examples_by_intent:
                    examples_by_intent[intent] = []

                examples_by_intent[intent].append({
                    'input': record['input'],
                    'intent': intent,
                    'confidence': record['confidence']
                })

        # Filter: only return if we have enough examples
        filtered = {}
        for intent, examples in examples_by_intent.items():
            if len(examples) >= min_count:
                # Sort by confidence and take top N
                examples.sort(key=lambda x: x['confidence'], reverse=True)
                filtered[intent] = examples[:200]

        return filtered
```

### Supervisorì— í†µí•©

```python
# backend/core/supervisor.py

from core.example_collector import IncrementalExampleCollector

class SupervisorAgent:
    def __init__(self):
        # ...
        self.example_collector = IncrementalExampleCollector()

    def analyze_request(self, request: str, context: Optional[List] = None) -> dict:
        """Analyze with example collection"""

        analysis = self._perform_analysis(request, context)

        # Record this classification
        self.example_collector.record_classification(
            user_input=request,
            predicted_intent=analysis['intent'],
            confidence=analysis['confidence_score']
        )

        return analysis
```

---

## ê¶Œì¥ ì „ëµ: Hybrid Approach

**Phase 1 (Day 1):** LLMìœ¼ë¡œ ì´ˆê¸° ì˜ˆì‹œ ìƒì„± (250ê°œ)
```bash
python scripts/generate_few_shot_examples.py
```

**Phase 2 (Day 2-7):** ì‹¤ì œ ì‚¬ìš©í•˜ë©´ì„œ ì ì§„ì  ìˆ˜ì§‘
- ìë™ìœ¼ë¡œ high-confidence ë¶„ë¥˜ ê¸°ë¡
- ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

**Phase 3 (Week 2+):** ë¡œê·¸ ë¶„ì„ìœ¼ë¡œ ë³´ê°•
```bash
python scripts/collect_from_logs.py
```

**Phase 4 (Long-term):** ê³µê°œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‹¤ì–‘ì„± ì¶”ê°€
- íŠ¹ì • ë„ë©”ì¸ì´ ë¶€ì¡±í•  ë•Œ
- íŠ¹ì • ì–¸ì–´ê°€ ë¶€ì¡±í•  ë•Œ

---

## ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬

### ìë™ ê²€ì¦

```python
def validate_example_quality(examples: List[Dict]) -> float:
    """ì˜ˆì‹œ í’ˆì§ˆ ìë™ ê²€ì¦"""
    supervisor = SupervisorAgent()

    correct = 0
    total = len(examples)

    for ex in examples:
        predicted = supervisor.analyze_request(ex['input'])
        if predicted['intent'] == ex['intent']:
            correct += 1

    return correct / total
```

### ì£¼ê¸°ì  ë¦¬ë·°

```python
# ë§¤ì£¼ ì‹¤í–‰
python scripts/review_examples.py

# Output:
# ğŸ“Š Example Quality Report:
#    simple_conversation: 95% accuracy (50 examples)
#    capability_question: 88% accuracy (45 examples)
#    âš ï¸ coding_task: 72% accuracy (need review!)
```

---

## ìš”ì•½

| ë°©ë²• | ì¦‰ì‹œ ì‹œì‘ | í’ˆì§ˆ | ë¹„ìš© | ì¶”ì²œ |
|------|----------|------|------|------|
| ğŸ¤– **LLM ìƒì„±** | âœ… | ì¤‘-ê³  | ë‚®ìŒ | â­â­â­â­â­ |
| ğŸ“Š **ë¡œê·¸ ë¶„ì„** | âš ï¸ (ë°ì´í„° í•„ìš”) | ìµœê³  | ë¬´ë£Œ | â­â­â­â­ |
| ğŸŒ **ê³µê°œ ë°ì´í„°ì…‹** | âœ… | ì¤‘ | ë¬´ë£Œ | â­â­â­ |
| ğŸ“ˆ **ì ì§„ì  ìˆ˜ì§‘** | âš ï¸ (ì‹œê°„ í•„ìš”) | ìµœê³  | ë¬´ë£Œ | â­â­â­â­â­ |

**ìµœì  ì „ëµ**: LLM ìƒì„±ìœ¼ë¡œ ì‹œì‘ â†’ ì ì§„ì  ìˆ˜ì§‘ìœ¼ë¡œ ê°œì„ 

ì´ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©ì ë¶€ë‹´ ì—†ì´ ê³ í’ˆì§ˆ ì˜ˆì‹œë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
