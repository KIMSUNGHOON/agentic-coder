# Agent Prompt Engineering í˜¸í™˜ì„± ê°ì‚¬ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2026-01-06
**ë²„ì „**: 1.0
**ëª©ì **: DeepSeek-R1, Qwen3, GPT-OSS ëª¨ë¸ ê°„ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ í˜¸í™˜ì„± ë¶„ì„ ë° ê°œì„  ê³„íš

---

## 1. ê°œìš”

ì´ ë¬¸ì„œëŠ” TestCodeAgentì˜ ëª¨ë“  ì—ì´ì „íŠ¸ ë…¸ë“œì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í˜¸í™˜ì„± ì „ìˆ˜ ì¡°ì‚¬ ê²°ê³¼ì…ë‹ˆë‹¤. ê° ëª¨ë¸ë³„ íŠ¹ì„±ê³¼ ì—ì´ì „íŠ¸ êµ¬í˜„ ìƒíƒœë¥¼ ë¶„ì„í•˜ê³ , ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ì‹ë³„í•©ë‹ˆë‹¤.

### 1.1 ì§€ì› ëª¨ë¸ ëª©ë¡
| ëª¨ë¸ | íŠ¹ì§• | í”„ë¡¬í”„íŠ¸ í˜•ì‹ |
|------|------|---------------|
| **DeepSeek-R1** | ì¶”ë¡  ëª¨ë¸, `<think></think>` íƒœê·¸ í•„ìˆ˜ | Chain-of-Thought with think tags |
| **Qwen3** | ë²”ìš© ì½”ë”© ëª¨ë¸ | Standard prompts (no special tags) |
| **GPT-OSS** | OpenAI Harmony í¬ë§·, ë‚´ë¶€ ì±„ë„ ì‚¬ìš© | Structured reasoning (no think tags) |

### 1.2 í•µì‹¬ ì°¨ì´ì 
```
DeepSeek-R1: <think>reasoning</think> â†’ final answer
Qwen3:       Direct response (no special tags)
GPT-OSS:     Internal Harmony channels â†’ final response
```

---

## 2. ì—ì´ì „íŠ¸ ë…¸ë“œ í˜¸í™˜ì„± ë¶„ì„

### 2.1 í˜¸í™˜ì„± ìƒíƒœ ìš”ì•½

| ë…¸ë“œ | íŒŒì¼ ê²½ë¡œ | ëª¨ë¸ ì¸ì‹ | ìƒíƒœ | ìš°ì„ ìˆœìœ„ |
|------|-----------|-----------|------|----------|
| Coder | `nodes/coder.py` | âœ… | ì–‘í˜¸ | - |
| Refiner | `nodes/refiner.py` | âœ… | ì–‘í˜¸ | - |
| Reviewer | `nodes/reviewer.py` | âš ï¸ | ë¶€ë¶„ì  | Medium |
| Architect | `nodes/architect.py` | âŒ | ë¯¸êµ¬í˜„ | High |
| RCA Analyzer | `nodes/rca_analyzer.py` | âŒ | ë¬¸ì œìˆìŒ | **Critical** |
| Security Gate | `nodes/security_gate.py` | N/A | ë¶ˆí•„ìš” | - |
| QA Gate | `nodes/qa_gate.py` | N/A | ë¶ˆí•„ìš” | - |
| Aggregator | `nodes/aggregator.py` | N/A | ë¶ˆí•„ìš” | - |
| Persistence | `nodes/persistence.py` | N/A | ë¶ˆí•„ìš” | - |
| Human Approval | `nodes/human_approval.py` | N/A | ë¶ˆí•„ìš” | - |
| Supervisor | `nodes/supervisor.py` | âœ… | ì–‘í˜¸ | - |

### 2.2 ìƒì„¸ ë¶„ì„

#### âœ… ì–‘í˜¸ (Model-Aware)

**1. Coder Node** (`backend/app/agent/langgraph/nodes/coder.py`)
- **êµ¬í˜„ ë°©ì‹**: `_get_code_generation_prompt()` í•¨ìˆ˜ë¡œ ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
- **ì§€ì› ëª¨ë¸**: Qwen, DeepSeek, Generic (GPT-OSS í¬í•¨)
- **ì½”ë“œ ìœ„ì¹˜**: Line 33-116

```python
def _get_code_generation_prompt(user_request: str, task_type: str) -> tuple:
    model_type = settings.get_coding_model_type
    if model_type == "qwen":
        # Qwen specific prompt
    elif model_type == "deepseek":
        # DeepSeek with <think> tags
    else:
        # Generic/GPT-OSS prompt
```

**2. Refiner Node** (`backend/app/agent/langgraph/nodes/refiner.py`)
- **êµ¬í˜„ ë°©ì‹**: `get_refiner_analysis_prompt()` í•¨ìˆ˜ë¡œ ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
- **ì§€ì› ëª¨ë¸**: DeepSeek, GPT-OSS, Generic/Qwen
- **ì½”ë“œ ìœ„ì¹˜**: Line 81-181

```python
def get_refiner_analysis_prompt(model_type: str, issues: list, ...):
    if model_type == "deepseek":
        return """<think>...</think>"""
    elif model_type in ("gpt-oss", "gpt"):
        return """## Issues to Fix..."""
    else:
        return """Fix the following code issues..."""
```

**3. Supervisor** (`backend/core/supervisor.py`)
- **êµ¬í˜„ ë°©ì‹**: `settings.get_reasoning_model_type`ìœ¼ë¡œ ëª¨ë¸ ê°ì§€ í›„ í”„ë¡¬í”„íŠ¸ ì„ íƒ
- **ì§€ì› ëª¨ë¸**: DeepSeek, GPT-OSS, Generic
- **ìˆ˜ì • ì´ë ¥**: 2026-01-06 ì„¸ì…˜ì—ì„œ GPT-OSS í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬ ì™„ë£Œ

---

#### âš ï¸ ë¶€ë¶„ì  í˜¸í™˜ (Needs Improvement)

**1. Reviewer Node** (`backend/app/agent/langgraph/nodes/reviewer.py`)

**í˜„ì¬ ìƒíƒœ**:
- LLMProviderFactory ì‚¬ìš© ì‹œ: ëª¨ë¸ ì–´ëŒ‘í„°ê°€ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
- ì§ì ‘ HTTP í˜¸ì¶œ ì‹œ: Generic í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš© (Line 196-209)

**ë¬¸ì œì **:
```python
# Line 196-209: Direct HTTP call uses generic prompt only
prompt = f"""You are an expert code reviewer..."""
# No model-specific adaptation
```

**ê°œì„  ë°©ì•ˆ**:
```python
def _get_review_prompt(model_type: str, review_context: str) -> str:
    if model_type == "deepseek":
        return f"""<think>
1. Analyze code correctness
2. Check security issues
3. Evaluate performance
</think>
{review_context}"""
    elif model_type == "gpt-oss":
        return f"""## Code Review Task
{review_context}
Return in JSON format..."""
    else:
        return f"""Review the following code...\n{review_context}"""
```

---

#### âŒ ë¬¸ì œ ìˆìŒ (Critical Issues)

**1. RCA Analyzer Node** (`backend/app/agent/langgraph/nodes/rca_analyzer.py`)

**ì‹¬ê°ë„**: ğŸ”´ Critical

**í˜„ì¬ ìƒíƒœ**:
- DeepSeek-R1 ì „ìš© í”„ë¡¬í”„íŠ¸ í•˜ë“œì½”ë”© (Line 17)
- ëª¨ë“  ëª¨ë¸ì— `<think>` íƒœê·¸ ì¶œë ¥ (Line 80-97)

```python
# Line 17: Hardcoded import
from shared.prompts.deepseek_r1 import DEEPSEEK_R1_LOOP_ANALYSIS_PROMPT

# Line 80-97: Always generates <think> tags
rca_analysis = f"""<think>
1. Pattern Analysis: Reviewing {len(issues)} issues...
...
</think>"""
```

**ë¬¸ì œì **:
- GPT-OSS, Qwen ì‚¬ìš© ì‹œì—ë„ `<think>` íƒœê·¸ê°€ ì¶œë ¥ë¨
- ëª¨ë¸ íƒ€ì… ê°ì§€ ë¡œì§ ì—†ìŒ
- ì‘ë‹µ íŒŒì‹± ì‹œ `<think>` íƒœê·¸ê°€ UIì— ë…¸ì¶œë  ìˆ˜ ìˆìŒ

**ê°œì„  í•„ìš” ì‘ì—…**:
1. ëª¨ë¸ íƒ€ì… ê°ì§€ ë¡œì§ ì¶”ê°€
2. ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸° êµ¬í˜„
3. ì‘ë‹µì—ì„œ `<think>` íƒœê·¸ ì¡°ê±´ë¶€ ìƒì„±

---

**2. Architect Node** (`backend/app/agent/langgraph/nodes/architect.py`)

**ì‹¬ê°ë„**: ğŸŸ¡ High

**í˜„ì¬ ìƒíƒœ**:
- LLM í†µí•© ë¯¸ì™„ë£Œ (Line 188-189)
- Rule-based í´ë°±ë§Œ ì‚¬ìš© ì¤‘

```python
# Line 188-189: TODO comment indicating incomplete integration
# TODO: Integrate with DeepSeek-R1 for intelligent design
architecture = _generate_architecture(user_request, workspace_root, supervisor_analysis)
```

**ë¬¸ì œì **:
- í”„ë¡¬í”„íŠ¸ëŠ” ì •ì˜ë˜ì–´ ìˆìœ¼ë‚˜ (Line 25-120) ì‹¤ì œ LLM í˜¸ì¶œ ì—†ìŒ
- `_generate_architecture()` í•¨ìˆ˜ê°€ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ê·œì¹™ë§Œ ì‚¬ìš©
- ë³µì¡í•œ í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„ ì‹œ í’ˆì§ˆ ì €í•˜

**ê°œì„  í•„ìš” ì‘ì—…**:
1. LLM í†µí•© êµ¬í˜„ (coder.py íŒ¨í„´ ì°¸ì¡°)
2. ëª¨ë¸ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
3. í´ë°± ë¡œì§ ìœ ì§€í•˜ë˜ LLM ìš°ì„  ì‹œë„

---

## 3. LLM Provider ì•„í‚¤í…ì²˜ ë¶„ì„

### 3.1 íŒŒì¼ êµ¬ì¡°
```
shared/llm/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py                    # BaseLLMProvider ì¶”ìƒ í´ë˜ìŠ¤
â””â”€â”€ adapters/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ deepseek_adapter.py    # DeepSeek-R1 ì–´ëŒ‘í„°
    â”œâ”€â”€ gpt_oss_adapter.py     # GPT-OSS ì–´ëŒ‘í„°
    â”œâ”€â”€ qwen_adapter.py        # Qwen ì–´ëŒ‘í„°
    â””â”€â”€ generic_adapter.py     # ë²”ìš© ì–´ëŒ‘í„°
```

### 3.2 ì–´ëŒ‘í„° êµ¬í˜„ ìƒíƒœ

| ì–´ëŒ‘í„° | í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… | ì‘ë‹µ íŒŒì‹± | Think íƒœê·¸ ì²˜ë¦¬ |
|--------|-----------------|-----------|-----------------|
| DeepSeek | âœ… | âœ… | âœ… ì¶”ì¶œ ë° ë¶„ë¦¬ |
| GPT-OSS | âœ… | âœ… | N/A (Harmony ì±„ë„) |
| Qwen | âœ… | âœ… | N/A |
| Generic | âœ… | âœ… | âœ… í´ë°± ì²˜ë¦¬ |

### 3.3 ì‘ë‹µ íŒŒì‹± ë¡œì§ (`base.py:_extract_json`)
```python
def _extract_json(self, text: str) -> Optional[Dict]:
    # Step 1: Remove <think>...</think> tags
    cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    # Step 2: Remove other wrapper tags
    cleaned_text = re.sub(r'<reasoning>.*?</reasoning>', '', cleaned_text, flags=re.DOTALL)

    # Step 3-6: JSON extraction logic
    ...
```

**ê²°ë¡ **: LLM Provider ë ˆì´ì–´ëŠ” ì˜ ì„¤ê³„ë˜ì–´ ìˆìœ¼ë©°, ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ í˜¸í™˜ì„± ë¬¸ì œëŠ” Providerë¥¼ í†µí•˜ì§€ ì•ŠëŠ” ì§ì ‘ í˜¸ì¶œì—ì„œ ë°œìƒ

---

## 4. í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¶„ì„

### 4.1 íŒŒì¼ ëª©ë¡
```
shared/prompts/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ deepseek_r1.py    # DeepSeek-R1 ì „ìš© (DEEPSEEK_R1_SYSTEM_PROMPT, etc.)
â”œâ”€â”€ gpt_oss.py        # GPT-OSS ì „ìš© (GPT_OSS_SYSTEM_PROMPT, etc.)
â”œâ”€â”€ qwen_coder.py     # Qwen Coder ì „ìš©
â””â”€â”€ generic.py        # ë²”ìš© í”„ë¡¬í”„íŠ¸
```

### 4.2 í”„ë¡¬í”„íŠ¸ í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤

| í”„ë¡¬í”„íŠ¸ | DeepSeek | GPT-OSS | Qwen | ìš©ë„ |
|----------|----------|---------|------|------|
| DEEPSEEK_R1_SYSTEM_PROMPT | âœ… | âŒ | âŒ | Supervisor ì¶”ë¡  |
| GPT_OSS_SYSTEM_PROMPT | âŒ | âœ… | âš ï¸ | Supervisor ì¶”ë¡  |
| QWEN_CODER_SYSTEM_PROMPT | âŒ | âŒ | âœ… | ì½”ë“œ ìƒì„± |
| GENERIC_CODE_GENERATION_PROMPT | âš ï¸ | âš ï¸ | âš ï¸ | ë²”ìš© ì½”ë“œ ìƒì„± |

---

## 5. ê°œì„  ê³„íš

### 5.1 ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤

| ìš°ì„ ìˆœìœ„ | ì‘ì—… | ë‚œì´ë„ | ì˜í–¥ë„ | ì˜ˆìƒ ì‘ì—…ëŸ‰ |
|----------|------|--------|--------|-------------|
| ğŸ”´ P0 | RCA Analyzer ëª¨ë¸ í˜¸í™˜ì„± ìˆ˜ì • | Medium | Critical | 2-3ì‹œê°„ |
| ğŸŸ¡ P1 | Architect Node LLM í†µí•© | High | High | 4-6ì‹œê°„ |
| ğŸŸ¡ P1 | Reviewer Node í”„ë¡¬í”„íŠ¸ ë¶„ê¸° | Low | Medium | 1-2ì‹œê°„ |
| ğŸŸ¢ P2 | ì „ì²´ ë…¸ë“œ LLMProvider í‘œì¤€í™” | Medium | High | 8ì‹œê°„+ |

### 5.2 P0: RCA Analyzer ìˆ˜ì •

**íŒŒì¼**: `backend/app/agent/langgraph/nodes/rca_analyzer.py`

**ë³€ê²½ ì‚¬í•­**:
1. ëª¨ë¸ íƒ€ì… ê°ì§€ ì¶”ê°€
2. ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸° êµ¬í˜„
3. `<think>` íƒœê·¸ ì¡°ê±´ë¶€ ìƒì„±

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
from app.core.config import settings

# Import model-specific prompts
from shared.prompts.deepseek_r1 import DEEPSEEK_R1_LOOP_ANALYSIS_PROMPT
from shared.prompts.gpt_oss import GPT_OSS_SUPERVISOR_PROMPT  # New

def _get_rca_prompt(model_type: str, context: dict) -> str:
    if model_type == "deepseek":
        return DEEPSEEK_R1_LOOP_ANALYSIS_PROMPT.format(**context)
    elif model_type == "gpt-oss":
        return f"""## Root Cause Analysis
Analyze the refinement loop issue:
- Max iterations: {context['max_iterations']}
- Current iteration: {context['current_iteration']}

Provide analysis in JSON format..."""
    else:
        return f"""Analyze the following issue..."""

def rca_analyzer_node(state: QualityGateState) -> Dict:
    model_type = settings.get_reasoning_model_type

    # Generate model-appropriate analysis
    if model_type == "deepseek":
        rca_analysis = f"""<think>
1. Pattern Analysis...
</think>

Analysis: ..."""
    else:
        rca_analysis = f"""## Refinement Analysis
**Issues Analyzed:** {len(issues)} problems found
..."""
```

### 5.3 P1: Architect Node LLM í†µí•©

**íŒŒì¼**: `backend/app/agent/langgraph/nodes/architect.py`

**ë³€ê²½ ì‚¬í•­**:
1. vLLM ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ì¶”ê°€
2. ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
3. JSON ì‘ë‹µ íŒŒì‹±
4. í´ë°± ë¡œì§ ìœ ì§€

**êµ¬í˜„ íŒ¨í„´** (coder.py ì°¸ì¡°):
```python
def _generate_architecture_with_llm(user_request: str, ...) -> Dict:
    endpoint = settings.get_reasoning_endpoint
    model = settings.get_reasoning_model
    model_type = settings.get_reasoning_model_type

    prompt = _get_architect_prompt(model_type, user_request)

    try:
        response = httpx.post(f"{endpoint}/chat/completions", ...)
        return _parse_architecture_response(response.json())
    except:
        return _generate_architecture(...)  # Fallback
```

### 5.4 P2: LLMProvider í‘œì¤€í™”

**ëª©í‘œ**: ëª¨ë“  ë…¸ë“œì—ì„œ ì§ì ‘ HTTP í˜¸ì¶œ ëŒ€ì‹  `LLMProviderFactory` ì‚¬ìš©

**ì¥ì **:
- ìë™ ëª¨ë¸ ê°ì§€ ë° í”„ë¡¬í”„íŠ¸ ì ìš©
- ì‘ë‹µ íŒŒì‹± í‘œì¤€í™”
- retry/backoff ë¡œì§ ì¬ì‚¬ìš©
- Think íƒœê·¸ ìë™ ì²˜ë¦¬

**ëŒ€ìƒ ë…¸ë“œ**:
- reviewer.py (ì§ì ‘ HTTP í˜¸ì¶œ ë¶€ë¶„)
- architect.py (LLM í†µí•© ì‹œ)
- rca_analyzer.py (ìˆ˜ì • ì‹œ)

---

## 6. ê°œë°œ ì—°ì†ì„±ì„ ìœ„í•œ ì°¸ì¡° ì •ë³´

### 6.1 í•µì‹¬ ì„¤ì • ìœ„ì¹˜
```
backend/app/core/config.py:
  - get_reasoning_model_type: ì¶”ë¡  ëª¨ë¸ íƒ€ì… ë°˜í™˜
  - get_coding_model_type: ì½”ë”© ëª¨ë¸ íƒ€ì… ë°˜í™˜
  - get_reasoning_endpoint: ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸
  - get_coding_endpoint: ì½”ë”© ì—”ë“œí¬ì¸íŠ¸
```

### 6.2 ëª¨ë¸ íƒ€ì… ê°ì§€ ë¡œì§
```python
@property
def get_reasoning_model_type(self) -> str:
    model_name = self.get_reasoning_model.lower()
    if "deepseek" in model_name:
        return "deepseek"
    elif "gpt-oss" in model_name or "gptoss" in model_name:
        return "gpt-oss"
    elif "qwen" in model_name:
        return "qwen"
    else:
        return "generic"
```

### 6.3 í”„ë¡¬í”„íŠ¸ ì‘ì„± ê°€ì´ë“œë¼ì¸

**DeepSeek-R1**:
```
<think>
1. Step-by-step reasoning
2. Multiple approaches
3. Final decision
</think>

[Structured final answer]
```

**GPT-OSS**:
```
## Section Header
Clear structured content without special tags.
JSON output when specified.
```

**Qwen/Generic**:
```
Direct instructions without special formatting.
Clear, concise prompts.
```

---

## 7. í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 7.1 ë³€ê²½ í›„ ê²€ì¦ í•­ëª©
- [ ] DeepSeek-R1ìœ¼ë¡œ Planning ëª¨ë“œ í…ŒìŠ¤íŠ¸ (`<think>` íƒœê·¸ ì •ìƒ ì¶œë ¥)
- [ ] GPT-OSSë¡œ Planning ëª¨ë“œ í…ŒìŠ¤íŠ¸ (`<think>` íƒœê·¸ ë¯¸ì¶œë ¥ í™•ì¸)
- [ ] Qwenìœ¼ë¡œ ì½”ë“œ ìƒì„± í…ŒìŠ¤íŠ¸
- [ ] RCA Analyzer ëª¨ë¸ë³„ ì¶œë ¥ í™•ì¸
- [ ] Reviewer í”¼ë“œë°± í˜•ì‹ í™•ì¸
- [ ] Architect LLM í†µí•© í›„ êµ¬ì¡° ì„¤ê³„ í’ˆì§ˆ í™•ì¸

### 7.2 íšŒê·€ í…ŒìŠ¤íŠ¸
- [ ] ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ì •ìƒ ë™ì‘
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° í´ë°± ë¡œì§
- [ ] í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 

---

## 8. ê²°ë¡ 

### 8.1 í˜„ì¬ ìƒíƒœ ìš”ì•½
- **ì–‘í˜¸**: Coder, Refiner, Supervisor - ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸° êµ¬í˜„ë¨
- **ê°œì„  í•„ìš”**: Reviewer - ë¶€ë¶„ì  ì§€ì›
- **ê¸´ê¸‰ ìˆ˜ì •**: RCA Analyzer - DeepSeek í•˜ë“œì½”ë”©, `<think>` íƒœê·¸ ê°•ì œ ì¶œë ¥
- **êµ¬í˜„ í•„ìš”**: Architect - LLM í†µí•© ë¯¸ì™„ë£Œ

### 8.2 ê¶Œì¥ ì‘ì—… ìˆœì„œ
1. **ì¦‰ì‹œ**: RCA Analyzer ëª¨ë¸ í˜¸í™˜ì„± ìˆ˜ì •
2. **ë‹¨ê¸°**: Architect LLM í†µí•©
3. **ì¤‘ê¸°**: LLMProvider í‘œì¤€í™”

### 8.3 ì°¸ê³  ë¬¸ì„œ
- `shared/llm/base.py` - LLM Provider ì¸í„°í˜ì´ìŠ¤
- `shared/prompts/*.py` - ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- `backend/core/supervisor.py` - ëª¨ë¸ ê°ì§€ íŒ¨í„´ ì°¸ì¡°

---

*ì´ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ì„¸ì…˜ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ìƒì„¸íˆ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.*
