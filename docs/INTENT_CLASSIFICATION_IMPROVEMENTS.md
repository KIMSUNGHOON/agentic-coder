# Intent Classification ê°œì„  ê³„íš (Improvement Roadmap)

**ì‘ì„±ì¼**: 2026-01-14
**í˜„ì¬ ìƒíƒœ**: Rule-based + LLM Hybrid (81.5% ì •í™•ë„)
**ëª©í‘œ**: 95%+ ì •í™•ë„, ë‹¤ì–‘í•œ ì‚¬ìš©ì ì…ë ¥ íŒ¨í„´ ëŒ€ì‘

---

## í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„

### âœ… ì˜ ì‘ë™í•˜ëŠ” ë¶€ë¶„
1. **Hybrid Architecture**: Rule-based (ë¹ ë¦„) + LLM (ì •í™•í•¨) ì¡°í•©
2. **2-Step Classification**: Intent â†’ Workflow ê²°ì •
3. **Pattern Detection**: ì¸ì‚¬, capability question íŒ¨í„´ ê°ì§€
4. **Direct Response**: Workflow ì—†ì´ ì¦‰ì‹œ ì‘ë‹µ (simple_conversation, simple_question)

### âš ï¸ ê°œì„  í•„ìš” ì˜ì—­
1. **Edge Cases**: ì• ë§¤í•œ ì…ë ¥ì— ëŒ€í•œ ì²˜ë¦¬ (confidence < 0.7)
2. **Context Awareness**: ì´ì „ ëŒ€í™” ë§¥ë½ ë¯¸í™œìš©
3. **Learning**: ì˜ëª»ëœ ë¶„ë¥˜ì—ì„œ í•™ìŠµí•˜ì§€ ëª»í•¨
4. **Multilingual**: í•œêµ­ì–´/ì˜ì–´ ì™¸ ì–¸ì–´ ë¯¸ì§€ì›

---

## ê°œì„  ê³„íš (ìš°ì„ ìˆœìœ„ ìˆœ)

### Phase 1: Few-Shot Learning ê°•í™” (ìš°ì„ ìˆœìœ„: ğŸ”´ HIGH)

**í˜„ì¬ ë¬¸ì œ:**
- LLMì— ì˜ˆì‹œë¥¼ ì œê³µí•˜ì§€ë§Œ ì²´ê³„ì ì´ì§€ ì•ŠìŒ
- Boundary case ì˜ˆì‹œê°€ promptì—ë§Œ ìˆê³  ë™ì ìœ¼ë¡œ ì„ íƒë˜ì§€ ì•ŠìŒ

**ëª©í‘œ:**
- ìœ ì‚¬í•œ ì˜ˆì‹œë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ì—¬ LLMì— ì œê³µ
- Few-shot accuracyë¥¼ 85% â†’ 92%ë¡œ í–¥ìƒ

**êµ¬í˜„ ë°©ë²•:**

```python
# backend/core/supervisor.py

# 1. Few-shot ì˜ˆì‹œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
FEW_SHOT_EXAMPLES = {
    "simple_conversation": [
        ("ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"),
        ("Hello", "Hi! How can I help you today?"),
        ("ê°ì‚¬í•©ë‹ˆë‹¤", "ì²œë§Œì—ìš”! ë˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”."),
        ("Thank you", "You're welcome! Let me know if you need anything else."),
    ],
    "simple_question": [
        ("ê³„íšë„ ì‘ì„± ê°€ëŠ¥í•©ë‹ˆê¹Œ?", "ë„¤, ì €ëŠ” í”„ë¡œì íŠ¸ ê³„íš, ì•„í‚¤í…ì²˜ ì„¤ê³„, êµ¬í˜„ ê³„íš ë“±ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."),
        ("Can you write plans?", "Yes, I can create project plans, architecture designs, and implementation roadmaps."),
        ("Pythonì´ ë­ì•¼?", "Pythonì€ ê°„ê²°í•œ ë¬¸ë²•ê³¼ ë†’ì€ ê°€ë…ì„±ìœ¼ë¡œ ìœ ëª…í•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤."),
        ("What is Python?", "Python is a high-level programming language known for its simple syntax and readability."),
    ],
    "capability_question": [
        ("ì½”ë“œ ë¦¬ë·° í•  ìˆ˜ ìˆì–´?", "ë„¤, ì €ëŠ” ì½”ë“œ ë¦¬ë·°ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë“œë¥¼ ê³µìœ í•´ì£¼ì‹œë©´ ë¦¬ë·°í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."),
        ("Are you able to debug?", "Yes, I can help debug code. Please share the code and error details."),
        ("í…ŒìŠ¤íŠ¸ ì‘ì„± ì§€ì›í•˜ë‚˜ìš”?", "ë„¤, ë‹¨ìœ„ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸ ë“± ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."),
    ],
    "coding_task": [
        ("REST APIë¥¼ ë§Œë“¤ì–´ì¤˜", "[workflow ìƒì„±]"),
        ("Create a Flask server", "[workflow ìƒì„±]"),
        ("ì´ ì½”ë“œë¥¼ ë¦¬ë·°í•´ì¤˜", "[workflow ìƒì„±]"),
    ],
    "mixed_intent": [
        ("ì•ˆë…•! Pythonìœ¼ë¡œ ì›¹ì„œë²„ ë§Œë“¤ì–´ì¤˜", "[workflow ìƒì„±] - ì¸ì‚¬ëŠ” ìˆì§€ë§Œ ì£¼ ì˜ë„ëŠ” ì½”ë“œ ìƒì„±"),
        ("Hi! Can you explain REST API?", "[direct response] - ì¸ì‚¬ + ì§ˆë¬¸ì´ì§€ë§Œ ì£¼ ì˜ë„ëŠ” ì„¤ëª… ìš”ì²­"),
    ]
}

# 2. ìœ ì‚¬ë„ ê¸°ë°˜ ì˜ˆì‹œ ì„ íƒ (Semantic Search)
def _select_relevant_examples(self, request: str, k: int = 3) -> List[Tuple[str, str]]:
    """
    í˜„ì¬ ìš”ì²­ê³¼ ê°€ì¥ ìœ ì‚¬í•œ kê°œì˜ ì˜ˆì‹œë¥¼ ì„ íƒ

    Args:
        request: ì‚¬ìš©ì ìš”ì²­
        k: ë°˜í™˜í•  ì˜ˆì‹œ ê°œìˆ˜

    Returns:
        List of (example_input, expected_output) tuples
    """
    # TODO: Implement semantic similarity using embeddings
    # For now, use simple keyword matching
    request_lower = request.lower()

    relevant_examples = []

    # Check which category is most relevant
    if self._is_greeting(request_lower):
        relevant_examples = FEW_SHOT_EXAMPLES["simple_conversation"][:k]
    elif self._is_capability_question(request_lower):
        relevant_examples = FEW_SHOT_EXAMPLES["capability_question"][:k]
    elif self._has_code_intent(request_lower):
        relevant_examples = FEW_SHOT_EXAMPLES["coding_task"][:k]
    else:
        relevant_examples = FEW_SHOT_EXAMPLES["simple_question"][:k]

    return relevant_examples

# 3. Few-shot prompt êµ¬ì„±
def _build_few_shot_prompt(self, request: str, examples: List[Tuple[str, str]]) -> str:
    """Few-shot ì˜ˆì‹œë¥¼ í¬í•¨í•œ prompt êµ¬ì„±"""
    examples_text = "\n\n".join([
        f"User: {inp}\nIntent: {out}"
        for inp, out in examples
    ])

    return f"""Based on these examples:

{examples_text}

Now classify this request:
User: {request}
Intent: """
```

**ì˜ˆìƒ íš¨ê³¼:**
- Accuracy: 81.5% â†’ 92%
- Edge case ì²˜ë¦¬ ê°œì„ 
- ë¹„ìš©: ê¸°ì¡´ LLM í˜¸ì¶œê³¼ ë™ì¼ (ì˜ˆì‹œë§Œ ì¶”ê°€)

**êµ¬í˜„ ë‚œì´ë„:** â­â­ (Medium)

**ì¼ì •:** 1-2ì¼

---

### Phase 2: Confidence Score & Clarification (ìš°ì„ ìˆœìœ„: ğŸŸ¡ MEDIUM)

**í˜„ì¬ ë¬¸ì œ:**
- Confidence scoreë¥¼ ë°˜í™˜í•˜ì§€ë§Œ í™œìš©í•˜ì§€ ì•ŠìŒ
- ì• ë§¤í•œ ì…ë ¥ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ í™•ì¸í•˜ì§€ ì•ŠìŒ

**ëª©í‘œ:**
- ë‚®ì€ confidence ì…ë ¥ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ ëª…í™•í™” ìš”ì²­
- False positive workflow ìƒì„± ë°©ì§€

**êµ¬í˜„ ë°©ë²•:**

```python
# backend/core/supervisor.py

def analyze_request(self, request: str, context: Optional[List] = None) -> dict:
    """Analyze request with confidence scoring"""
    analysis = self._perform_analysis(request, context)

    # CRITICAL: Check confidence score
    if analysis["confidence_score"] < 0.7:
        # Low confidence - ask for clarification
        return {
            **analysis,
            "requires_clarification": True,
            "clarification_options": self._generate_clarification_options(request, analysis)
        }

    return analysis

def _generate_clarification_options(self, request: str, analysis: dict) -> List[dict]:
    """Generate clarification options for ambiguous requests"""
    options = []

    # Option 1: Provide information
    options.append({
        "type": "simple_question",
        "label": "ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° (ì •ë³´ ì œê³µ)",
        "description": "ìš”ì²­í•˜ì‹  ë‚´ìš©ì— ëŒ€í•œ ì„¤ëª…ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
    })

    # Option 2: Generate code/plan
    options.append({
        "type": "coding_task",
        "label": "ì½”ë“œ/ê³„íš ì‘ì„±í•˜ê¸° (Workflow ì‹¤í–‰)",
        "description": "ì‹¤ì œ ì½”ë“œë‚˜ ê³„íšì„ ì‘ì„±í•˜ì—¬ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
    })

    return options
```

```python
# backend/app/agent/unified_agent_manager.py

async def process_unified_request(self, ...):
    """Process request with clarification support"""
    analysis = self.supervisor.analyze_request(user_message, context)

    # NEW: Handle clarification requests
    if analysis.get("requires_clarification"):
        if stream:
            async def stream_clarification():
                yield StreamUpdate(
                    agent="supervisor",
                    update_type="clarification_needed",
                    status="waiting",
                    message="ì´ ìš”ì²­ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í• ê¹Œìš”?",
                    data={
                        "options": analysis["clarification_options"],
                        "original_intent": analysis["intent"],
                        "confidence": analysis["confidence_score"]
                    }
                )
            return stream_clarification()
```

**Frontend ë³€ê²½:**

```typescript
// frontend/src/components/WorkflowInterface.tsx

// Handle clarification requests
if (update.update_type === 'clarification_needed') {
  // Show modal with options
  const selectedOption = await showClarificationModal(update.data.options);

  // Re-submit with clarified intent
  await submitWithClarification(userMessage, selectedOption);
}
```

**ì˜ˆìƒ íš¨ê³¼:**
- False positive 30% ê°ì†Œ
- ì‚¬ìš©ì ê²½í—˜ ê°œì„  (ì˜ëª»ëœ workflow ìƒì„± ë°©ì§€)
- Accuracy: 92% â†’ 94%

**êµ¬í˜„ ë‚œì´ë„:** â­â­â­ (High - Frontend ë³€ê²½ í•„ìš”)

**ì¼ì •:** 2-3ì¼

---

### Phase 3: Feedback Loop & Learning (ìš°ì„ ìˆœìœ„: ğŸŸ¡ MEDIUM)

**í˜„ì¬ ë¬¸ì œ:**
- ì˜ëª»ëœ ë¶„ë¥˜ë¥¼ ìˆ˜ì •í•  ë°©ë²•ì´ ì—†ìŒ
- ì‚¬ìš©ì í”¼ë“œë°±ì„ í•™ìŠµì— í™œìš©í•˜ì§€ ëª»í•¨

**ëª©í‘œ:**
- ì‚¬ìš©ìê°€ ì˜ëª»ëœ ë¶„ë¥˜ë¥¼ ë³´ê³ í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥
- ë³´ê³ ëœ ë°ì´í„°ë¥¼ í•™ìŠµ ì˜ˆì‹œì— ì¶”ê°€

**êµ¬í˜„ ë°©ë²•:**

```python
# backend/core/feedback_store.py (NEW)

import json
from pathlib import Path
from typing import Dict, List
from datetime import datetime

class IntentFeedbackStore:
    """Store user feedback on intent classifications"""

    def __init__(self, feedback_file: str = "data/intent_feedback.jsonl"):
        self.feedback_file = Path(feedback_file)
        self.feedback_file.parent.mkdir(parents=True, exist_ok=True)

    def add_feedback(
        self,
        user_input: str,
        predicted_intent: str,
        correct_intent: str,
        confidence_score: float,
        user_comment: str = ""
    ):
        """Record user correction"""
        feedback = {
            "timestamp": datetime.utcnow().isoformat(),
            "user_input": user_input,
            "predicted_intent": predicted_intent,
            "correct_intent": correct_intent,
            "confidence_score": confidence_score,
            "user_comment": user_comment
        }

        # Append to JSONL file
        with open(self.feedback_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(feedback, ensure_ascii=False) + "\n")

    def get_corrections(self, limit: int = 100) -> List[Dict]:
        """Get recent corrections for training"""
        corrections = []

        if not self.feedback_file.exists():
            return corrections

        with open(self.feedback_file, "r", encoding="utf-8") as f:
            for line in f:
                corrections.append(json.loads(line))

        return corrections[-limit:]

    def update_few_shot_examples(self):
        """Update FEW_SHOT_EXAMPLES with corrections"""
        corrections = self.get_corrections()

        # Add high-confidence corrections to examples
        for correction in corrections:
            if correction["confidence_score"] < 0.6:  # Was very wrong
                # Add to few-shot examples
                intent = correction["correct_intent"]
                example = (correction["user_input"], intent)

                # Append to appropriate category
                # (Implementation depends on FEW_SHOT_EXAMPLES structure)
                pass
```

```python
# backend/app/api/main_routes.py (ADD endpoint)

@router.post("/feedback/intent")
async def submit_intent_feedback(
    user_input: str,
    predicted_intent: str,
    correct_intent: str,
    confidence_score: float,
    user_comment: str = ""
):
    """Submit feedback on incorrect intent classification"""
    feedback_store = IntentFeedbackStore()
    feedback_store.add_feedback(
        user_input=user_input,
        predicted_intent=predicted_intent,
        correct_intent=correct_intent,
        confidence_score=confidence_score,
        user_comment=user_comment
    )

    # Optionally: Update few-shot examples immediately
    # feedback_store.update_few_shot_examples()

    return {"success": True, "message": "Feedback recorded"}
```

**Frontend:**

```typescript
// Add "Report Wrong Classification" button in UI
<button onClick={() => reportWrongIntent(message, predictedIntent)}>
  ğŸš© ì˜ëª»ëœ ë¶„ë¥˜ ì‹ ê³ 
</button>
```

**ì˜ˆìƒ íš¨ê³¼:**
- ì§€ì†ì ì¸ ê°œì„  (ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì •í™•ë„ ìƒìŠ¹)
- ì‚¬ìš©ì ì°¸ì—¬ë„ ì¦ê°€
- Domain-specific íŒ¨í„´ í•™ìŠµ

**êµ¬í˜„ ë‚œì´ë„:** â­â­ (Medium)

**ì¼ì •:** 2ì¼

---

### Phase 4: Context-Aware Classification (ìš°ì„ ìˆœìœ„: ğŸŸ¢ LOW)

**í˜„ì¬ ë¬¸ì œ:**
- ì´ì „ ëŒ€í™” ë§¥ë½ì„ intent classificationì— í™œìš©í•˜ì§€ ì•ŠìŒ
- "ê·¸ëŸ¼ ì‘ì„±í•´ì¤˜" ê°™ì€ context-dependent ì…ë ¥ ì²˜ë¦¬ ë¶ˆê°€

**ëª©í‘œ:**
- ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í™œìš©í•œ ë§¥ë½ ê¸°ë°˜ ë¶„ë¥˜
- Context-dependent í‘œí˜„ ì´í•´

**êµ¬í˜„ ë°©ë²•:**

```python
# backend/core/supervisor.py

def analyze_request_with_context(
    self,
    request: str,
    conversation_history: List[Dict[str, str]]
) -> dict:
    """Analyze request considering conversation context"""

    # Extract context clues from history
    context_summary = self._summarize_context(conversation_history)

    # Example context patterns:
    # User: "ê³„íšë„ ì‘ì„± ê°€ëŠ¥í•©ë‹ˆê¹Œ?"
    # Bot: "ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤."
    # User: "ê·¸ëŸ¼ ì‘ì„±í•´ì¤˜" â† Context: referring to "ê³„íš ì‘ì„±"

    # Build context-aware prompt
    if conversation_history:
        last_user_msg = conversation_history[-2]["content"] if len(conversation_history) >= 2 else ""
        last_bot_msg = conversation_history[-1]["content"] if conversation_history else ""

        # Detect context-dependent phrases
        context_dependent = self._is_context_dependent(request)

        if context_dependent:
            # Resolve reference from context
            resolved_request = self._resolve_context(request, last_user_msg, last_bot_msg)
            return self.analyze_request(resolved_request)

    return self.analyze_request(request)

def _is_context_dependent(self, request: str) -> bool:
    """Check if request depends on previous context"""
    context_markers = [
        "ê·¸ëŸ¼", "ê·¸ëŸ¬ë©´", "ê·¸ë ‡ë‹¤ë©´",  # Korean: "then", "in that case"
        "ê·¸ê±°", "ê·¸ê²ƒ", "ì´ê±°", "ì €ê±°",  # Korean: "that", "this"
        "then", "in that case", "that one", "it"
    ]
    return any(marker in request.lower() for marker in context_markers)

def _resolve_context(
    self,
    request: str,
    prev_user: str,
    prev_bot: str
) -> str:
    """Resolve context-dependent request"""
    # Example:
    # prev_user: "ê³„íšë„ ì‘ì„± ê°€ëŠ¥í•©ë‹ˆê¹Œ?"
    # prev_bot: "ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤."
    # request: "ê·¸ëŸ¼ ì‘ì„±í•´ì¤˜"
    # â†’ resolved: "ê³„íšì„ ì‘ì„±í•´ì¤˜"

    # Simple heuristic: combine previous user request with current action
    if "ê·¸ëŸ¼" in request and "ê°€ëŠ¥" in prev_user:
        # Extract topic from previous question
        topic = self._extract_topic(prev_user)  # â†’ "ê³„íš"
        action = self._extract_action(request)   # â†’ "ì‘ì„±"

        return f"{topic}ì„ {action}"

    return request
```

**ì˜ˆìƒ íš¨ê³¼:**
- Multi-turn conversation ì •í™•ë„ í–¥ìƒ
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ì§€ì›
- Accuracy: 94% â†’ 95%+

**êµ¬í˜„ ë‚œì´ë„:** â­â­â­â­ (Very High - NLP ë³µì¡)

**ì¼ì •:** 3-5ì¼

---

### Phase 5: Advanced Techniques (ìš°ì„ ìˆœìœ„: ğŸ”µ FUTURE)

**ì—°êµ¬ ë°©í–¥:**

1. **Embedding-based Similarity Search**
   - ì‚¬ìš©ì ì…ë ¥ì„ ë²¡í„°í™”í•˜ì—¬ ìœ ì‚¬í•œ ì˜ˆì‹œ ê²€ìƒ‰
   - Tools: OpenAI Embeddings, Sentence-BERT
   - ì˜ˆìƒ íš¨ê³¼: Few-shot ì˜ˆì‹œ ì„ íƒ ì •í™•ë„ í–¥ìƒ

2. **Fine-tuned Intent Classifier**
   - BERT/RoBERTa ê¸°ë°˜ intent classifier í•™ìŠµ
   - ìˆ˜ì§‘ëœ feedback ë°ì´í„°ë¡œ fine-tuning
   - ì˜ˆìƒ íš¨ê³¼: 98%+ accuracy, ë‚®ì€ ë ˆì´í„´ì‹œ

3. **Multi-language Support**
   - ì¼ë³¸ì–´, ì¤‘êµ­ì–´, ìŠ¤í˜ì¸ì–´ ì§€ì›
   - ì–¸ì–´ë³„ few-shot ì˜ˆì‹œ êµ¬ì¶•
   - ì˜ˆìƒ íš¨ê³¼: Global ì‚¬ìš©ì ì§€ì›

4. **Confidence Calibration**
   - Confidence scoreë¥¼ ì‹¤ì œ ì •í™•ë„ì™€ ì¼ì¹˜ì‹œí‚¤ê¸°
   - Temperature scaling, Platt scaling
   - ì˜ˆìƒ íš¨ê³¼: ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” confidence score

---

## êµ¬í˜„ ìš°ì„ ìˆœìœ„ ë° ì¼ì •

| Phase | ìš°ì„ ìˆœìœ„ | ì˜ˆìƒ ê¸°ê°„ | ì˜ˆìƒ íš¨ê³¼ |
|-------|---------|-----------|-----------|
| **Phase 1: Few-Shot Learning** | ğŸ”´ HIGH | 1-2ì¼ | 81.5% â†’ 92% |
| **Phase 2: Confidence & Clarification** | ğŸŸ¡ MEDIUM | 2-3ì¼ | 92% â†’ 94% |
| **Phase 3: Feedback Loop** | ğŸŸ¡ MEDIUM | 2ì¼ | ì§€ì†ì  ê°œì„  |
| **Phase 4: Context-Aware** | ğŸŸ¢ LOW | 3-5ì¼ | 94% â†’ 95%+ |
| **Phase 5: Advanced Techniques** | ğŸ”µ FUTURE | 1-2ì£¼ | 95%+ â†’ 98%+ |

**Total Timeline**: 1-2ì£¼ (Phase 1-3 ì™„ë£Œ ì‹œ production-ready)

---

## ì„±ê³µ ì§€í‘œ (KPIs)

### ì •ëŸ‰ì  ì§€í‘œ
- **Intent Classification Accuracy**: 81.5% â†’ 95%+
- **False Positive Rate** (ë¶ˆí•„ìš”í•œ workflow): 18.5% â†’ 5% ì´í•˜
- **Clarification Rate**: ì• ë§¤í•œ ì…ë ¥ ì¤‘ ì‚¬ìš©ì í™•ì¸ ìš”ì²­ ë¹„ìœ¨ 20%+
- **User Correction Rate**: ì‚¬ìš©ìê°€ ë¶„ë¥˜ ìˆ˜ì •í•œ ë¹„ìœ¨ < 3%

### ì •ì„±ì  ì§€í‘œ
- ì‚¬ìš©ì ë§Œì¡±ë„ (ì¸ì‚¬ì— workflow ìƒì„± ì•ˆí•¨)
- Edge case ì²˜ë¦¬ ëŠ¥ë ¥ (capability question ë“±)
- Multi-turn conversation ìì—°ìŠ¤ëŸ¬ì›€

---

## ì°¸ê³  ìë£Œ

### Academic Papers
- [Intent Detection in the Age of LLMs (2024)](https://arxiv.org/html/2410.01627v1)
- [IntentGPT: Few-shot Intent Discovery (2024)](https://arxiv.org/html/2411.10670v1)
- [Intent Classification for Bank Chatbots through LLM Fine-Tuning (2024)](https://arxiv.org/html/2410.04925v1)

### Industry Best Practices
- [Hybrid LLM + Intent Classification Approach](https://medium.com/data-science-collective/intent-driven-natural-language-interface-a-hybrid-llm-intent-classification-approach-e1d96ad6f35d)
- [Benchmarking Hybrid LLM Classification Systems](https://www.voiceflow.com/pathways/benchmarking-hybrid-llm-classification-systems)
- [Intent Classification in 2026: What it is & How it Works](https://research.aimultiple.com/intent-classification/)

### Implementation Guides
- [LLM-Powered Chatbots: Practical Guide](https://ranjankumar.in/llm-powered-chatbots-a-practical-guide-to-user-input-classification-and-intent-handling/)
- [Intent Classification: 2025 Techniques for NLP Models](https://labelyourdata.com/articles/machine-learning/intent-classification)

---

## ë‹¤ìŒ ë‹¨ê³„

1. **Phase 1 êµ¬í˜„ ì‹œì‘** (Few-Shot Learning)
   - `FEW_SHOT_EXAMPLES` ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
   - `_select_relevant_examples()` êµ¬í˜„
   - `_build_few_shot_prompt()` êµ¬í˜„

2. **í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í™•ì¥**
   - Capability questions ì¶”ê°€
   - Context-dependent ì…ë ¥ ì¶”ê°€
   - Edge cases ì¶”ê°€

3. **Monitoring Dashboard êµ¬ì¶•**
   - Intent classification ì •í™•ë„ ì¶”ì 
   - False positive/negative ì¶”ì 
   - Confidence score ë¶„í¬

4. **Documentation ì—…ë°ì´íŠ¸**
   - API ë¬¸ì„œì— clarification flow ì¶”ê°€
   - Frontend ê°€ì´ë“œ ì—…ë°ì´íŠ¸

---

**ì‘ì„±ì**: Claude (Autonomous Analysis)
**Last Updated**: 2026-01-14
**Status**: ğŸ“ Planning Phase
