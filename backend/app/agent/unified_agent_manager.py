"""Unified Agent Manager - í†µí•© ì—ì´ì „íŠ¸ ë§¤ë‹ˆì €.

ì´ ëª¨ë“ˆì€ ëª¨ë“  ìš”ì²­ì„ Supervisorë¥¼ í†µí•´ ë¶„ì„í•˜ê³ 
ì ì ˆí•œ í•¸ë“¤ëŸ¬ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì¤‘ì•™ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.

Claude Code / OpenAI Codex ë°©ì‹ì˜ í†µí•© ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:
User Prompt â†’ Supervisor â†’ Handler â†’ Response
"""
import logging
import aiofiles
from pathlib import Path
from typing import Dict, Any, Optional, Union, AsyncGenerator, List
from datetime import datetime

from core.supervisor import SupervisorAgent
from core.response_aggregator import (
    ResponseAggregator,
    UnifiedResponse,
    ResponseType,
    StreamUpdate
)
from core.context_store import ContextStore, ConversationContext, get_context_store
from app.agent.handlers import (
    QuickQAHandler,
    PlanningHandler,
    CodeGenerationHandler,
    HandlerResult
)
from app.services.rag_context import get_rag_builder, RAGContext

logger = logging.getLogger(__name__)


class UnifiedAgentManager:
    """í†µí•© ì—ì´ì „íŠ¸ ë§¤ë‹ˆì €

    ëª¨ë“  ì‚¬ìš©ì ìš”ì²­ì„ Supervisorë¥¼ í†µí•´ ë¶„ì„í•˜ê³ 
    ì‘ë‹µ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ í•¸ë“¤ëŸ¬ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

    Flow:
    1. ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
    2. Supervisor ë¶„ì„
    3. ì‘ë‹µ íƒ€ì…ë³„ í•¸ë“¤ëŸ¬ ì‹¤í–‰
    4. ì‘ë‹µ ì§‘ê³„
    5. ì»¨í…ìŠ¤íŠ¸ ì €ì¥

    Attributes:
        supervisor: Supervisor ì—ì´ì „íŠ¸
        context_store: ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì†Œ
        response_aggregator: ì‘ë‹µ ì§‘ê³„ê¸°
        handlers: ì‘ë‹µ íƒ€ì…ë³„ í•¸ë“¤ëŸ¬ ë”•ì…”ë„ˆë¦¬
    """

    def __init__(self):
        """UnifiedAgentManager ì´ˆê¸°í™”"""
        # Supervisor ì´ˆê¸°í™” (API ëª¨ë“œ)
        self.supervisor = SupervisorAgent(use_api=True)

        # ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì†Œ
        self.context_store = get_context_store()

        # ì‘ë‹µ ì§‘ê³„ê¸°
        self.response_aggregator = ResponseAggregator()

        # ì‘ë‹µ íƒ€ì…ë³„ í•¸ë“¤ëŸ¬
        self.handlers = {
            ResponseType.QUICK_QA: QuickQAHandler(),
            ResponseType.PLANNING: PlanningHandler(),
            ResponseType.CODE_GENERATION: CodeGenerationHandler(),
            # CODE_REVIEWì™€ DEBUGGINGì€ CodeGenerationHandler ì¬ì‚¬ìš©
            ResponseType.CODE_REVIEW: CodeGenerationHandler(),
            ResponseType.DEBUGGING: CodeGenerationHandler(),
        }

        logger.info("UnifiedAgentManager initialized")

    async def process_request(
        self,
        session_id: str,
        user_message: str,
        workspace: Optional[str] = None,
        stream: bool = False
    ) -> Union[UnifiedResponse, AsyncGenerator[StreamUpdate, None]]:
        """í†µí•© ìš”ì²­ ì²˜ë¦¬

        Args:
            session_id: ì„¸ì…˜ ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            workspace: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ (ì˜µì…˜)
            stream: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì—¬ë¶€

        Returns:
            Union[UnifiedResponse, AsyncGenerator]: í†µí•© ì‘ë‹µ ë˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„°
        """
        logger.info(f"Processing request: session={session_id}, stream={stream}")
        start_time = datetime.now()

        try:
            # 1. ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
            context = await self.context_store.load(session_id)

            # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì—…ë°ì´íŠ¸ (ìˆëŠ” ê²½ìš°)
            if workspace:
                await self.context_store.update_workspace(session_id, workspace)
                context.workspace = workspace

            # 2. Supervisor ë¶„ì„ (RAG í†µí•©)
            logger.info("Running Supervisor analysis with RAG enrichment...")
            analysis = await self._analyze_request(user_message, context, session_id)

            response_type = analysis.get("response_type", ResponseType.QUICK_QA)
            logger.info(f"Response type determined: {response_type}")

            # CRITICAL: Check if workflow is NOT required and direct_response exists
            requires_workflow = analysis.get("requires_workflow", True)
            direct_response = analysis.get("direct_response")

            if not requires_workflow and direct_response:
                # Direct response - no need to call handler!
                logger.info(f"ğŸ’¬ Direct Response (No Handler Needed)")
                logger.info(f"   Intent: {analysis.get('intent')}")
                logger.info(f"   Response: {direct_response[:100]}...")

                if stream:
                    # Streaming mode - yield direct response as stream
                    async def stream_direct_response():
                        # Start
                        yield StreamUpdate(
                            agent="supervisor",
                            update_type="analysis",
                            status="completed",
                            message=f"ë¶„ì„ ì™„ë£Œ: {analysis.get('intent', 'simple_conversation')}",
                            data={"intent": analysis.get('intent')}
                        )

                        # Content
                        yield StreamUpdate(
                            agent="supervisor",
                            update_type="content",
                            status="streaming",
                            message=direct_response,
                            data={"handler_bypassed": True}
                        )

                        # Save context
                        await self.context_store.save(
                            session_id=session_id,
                            user_message=user_message,
                            assistant_response=direct_response,
                            analysis=analysis,
                            artifacts=[]
                        )

                        # Complete
                        elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000
                        yield StreamUpdate(
                            agent="supervisor",
                            update_type="complete",
                            status="completed",
                            message="ì‘ë‹µ ì™„ë£Œ",
                            data={
                                "latency_ms": int(elapsed_ms),
                                "session_id": session_id
                            }
                        )

                    return stream_direct_response()

                else:
                    # Non-streaming mode
                    result = HandlerResult(
                        content=direct_response,
                        thinking=analysis.get("analysis_summary", ""),
                        artifacts=[],
                        metadata={
                            "intent": analysis.get("intent"),
                            "requires_workflow": False,
                            "handler_bypassed": True
                        }
                    )

                    # Aggregate and save
                    response = self.response_aggregator.aggregate(result, analysis)

                    await self.context_store.save(
                        session_id=session_id,
                        user_message=user_message,
                        assistant_response=response.content,
                        analysis=response.analysis,
                        artifacts=response.artifacts
                    )

                    # Add metadata
                    elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000
                    response.metadata = response.metadata or {}
                    response.metadata["latency_ms"] = int(elapsed_ms)
                    response.metadata["session_id"] = session_id

                    logger.info(f"Request completed with direct response in {elapsed_ms:.0f}ms")
                    return response

            # 3. í•¸ë“¤ëŸ¬ ì„ íƒ
            handler = self.handlers.get(response_type)
            if not handler:
                handler = self.handlers[ResponseType.QUICK_QA]
                logger.warning(f"Unknown response type: {response_type}, using QuickQA")

            # 4. í•¸ë“¤ëŸ¬ ì‹¤í–‰
            if stream:
                # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ - direct_responseê°€ ìˆì–´ë„ ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹ìœ¼ë¡œ yield
                # (ìœ„ì—ì„œ ì´ë¯¸ ì²´í¬í–ˆì§€ë§Œ, requires_workflow=Trueì¸ ê²½ìš°ë§Œ ì—¬ê¸° ë„ë‹¬)
                return self._stream_response(
                    handler, user_message, analysis, context, session_id
                )
            else:
                # ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
                result = await handler.execute(user_message, analysis, context)

                # 5. ì‘ë‹µ ì§‘ê³„
                response = self.response_aggregator.aggregate(result, analysis)

                # 6. ì»¨í…ìŠ¤íŠ¸ ì €ì¥
                await self.context_store.save(
                    session_id=session_id,
                    user_message=user_message,
                    assistant_response=response.content,
                    analysis=response.analysis,
                    artifacts=response.artifacts
                )

                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000
                response.metadata = response.metadata or {}
                response.metadata["latency_ms"] = int(elapsed_ms)
                response.metadata["session_id"] = session_id

                logger.info(f"Request completed in {elapsed_ms:.0f}ms")
                return response

        except Exception as e:
            logger.error(f"Error processing request: {e}")
            return UnifiedResponse.from_error(str(e))

    async def _analyze_request(
        self,
        user_message: str,
        context: ConversationContext,
        session_id: str = "default"
    ) -> Dict[str, Any]:
        """Supervisorë¥¼ í†µí•œ ìš”ì²­ ë¶„ì„

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
            session_id: ì„¸ì…˜ ID (RAG ê²€ìƒ‰ìš©)

        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼
        """
        # RAG ì»¨í…ìŠ¤íŠ¸ë¡œ ìš”ì²­ ë³´ê°•
        enriched_message, rag_context = await self._enrich_with_rag(
            user_message, session_id
        )

        # ì»¨í…ìŠ¤íŠ¸ë¥¼ Supervisorì— ì „ë‹¬
        context_dict = context.to_dict() if context else None

        # Supervisor ë™ê¸° ë¶„ì„ ì‚¬ìš© (ë¹„ë™ê¸° ë²„ì „ì€ ìŠ¤íŠ¸ë¦¬ë°ìš©)
        analysis = self.supervisor.analyze_request(enriched_message, context_dict)

        # RAG ì •ë³´ë¥¼ ë¶„ì„ ê²°ê³¼ì— ì¶”ê°€
        if rag_context and (rag_context.results_count > 0 or rag_context.conversation_results > 0):
            analysis["rag_context"] = {
                "results_count": rag_context.results_count,
                "files_referenced": rag_context.files_referenced,
                "avg_relevance": rag_context.avg_relevance,
                "conversation_results": rag_context.conversation_results
            }
            logger.info(
                f"RAG enriched request with {rag_context.results_count} code results, "
                f"{rag_context.conversation_results} conversation results "
                f"(avg relevance: {rag_context.avg_relevance:.1%})"
            )

        return analysis

    async def _enrich_with_rag(
        self,
        user_message: str,
        session_id: str
    ) -> tuple[str, Optional[RAGContext]]:
        """RAG ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©ì ë©”ì‹œì§€ ë³´ê°•

        ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ì½”ë“œë¥¼ ì°¾ê³  ë©”ì‹œì§€ì— ì¶”ê°€í•©ë‹ˆë‹¤.

        Args:
            user_message: ì›ë³¸ ì‚¬ìš©ì ë©”ì‹œì§€
            session_id: ì„¸ì…˜ ID

        Returns:
            tuple[str, Optional[RAGContext]]: (ë³´ê°•ëœ ë©”ì‹œì§€, RAG ì»¨í…ìŠ¤íŠ¸)
        """
        try:
            rag_builder = get_rag_builder(session_id)
            enriched_message, rag_context = rag_builder.enrich_query(
                user_message,
                n_results=5,
                min_relevance=0.5
            )
            return enriched_message, rag_context
        except Exception as e:
            logger.warning(f"RAG enrichment failed: {e}")
            return user_message, None

    async def _stream_response(
        self,
        handler,
        user_message: str,
        analysis: Dict[str, Any],
        context: ConversationContext,
        session_id: str
    ) -> AsyncGenerator[StreamUpdate, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±

        Args:
            handler: í•¸ë“¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            analysis: Supervisor ë¶„ì„ ê²°ê³¼
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
            session_id: ì„¸ì…˜ ID

        Yields:
            StreamUpdate: ìŠ¤íŠ¸ë¦¬ë° ì—…ë°ì´íŠ¸
        """
        # RAG ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        rag_info = analysis.get("rag_context", {})
        rag_message = ""
        code_count = rag_info.get("results_count", 0)
        conv_count = rag_info.get("conversation_results", 0)
        if code_count > 0 or conv_count > 0:
            parts = []
            if code_count > 0:
                parts.append(f"{code_count}ê°œ ê´€ë ¨ ì½”ë“œ")
            if conv_count > 0:
                parts.append(f"{conv_count}ê°œ ê´€ë ¨ ëŒ€í™”")
            rag_message = f"\n- RAG ê²€ìƒ‰: {', '.join(parts)} ë°œê²¬"

        # Supervisor ë¶„ì„ ê²°ê³¼ ì „ì†¡
        yield StreamUpdate(
            agent="Supervisor",
            update_type="analysis",
            status="completed",
            message=f"ë¶„ì„ ì™„ë£Œ: {analysis.get('response_type', 'unknown')}",
            streaming_content=f"ìš”ì²­ ë¶„ì„ ê²°ê³¼:\n- ì‘ë‹µ ìœ í˜•: {analysis.get('response_type', 'unknown')}\n- ë³µì¡ë„: {analysis.get('complexity', 'unknown')}\n- ì‘ì—… ìœ í˜•: {analysis.get('task_type', 'unknown')}{rag_message}",
            data={
                "response_type": analysis.get("response_type"),
                "complexity": analysis.get("complexity"),
                "task_type": analysis.get("task_type"),
                "rag_context": rag_info if rag_info else None
            }
        )

        # í•¸ë“¤ëŸ¬ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
        artifacts = []
        final_content = ""
        plan_file = None
        workspace = context.workspace if context else None

        async for update in handler.execute_stream(user_message, analysis, context):
            # ì•„í‹°íŒ©íŠ¸ê°€ ìˆìœ¼ë©´ workspaceì— ì €ì¥
            if update.data and update.data.get("artifacts") and workspace:
                saved_artifacts = []
                for artifact in update.data["artifacts"]:
                    if artifact.get("content") and not artifact.get("saved"):
                        save_result = await self._save_artifact_to_workspace(artifact, workspace)
                        artifact.update(save_result)
                    saved_artifacts.append(artifact)
                update.data["artifacts"] = saved_artifacts

            yield update

            # ìµœì¢… ê²°ê³¼ ìˆ˜ì§‘
            if update.update_type == "completed" and update.data:
                if update.data.get("artifacts"):
                    artifacts.extend(update.data["artifacts"])
                if update.data.get("full_content"):
                    final_content = update.data["full_content"]
                if update.data.get("plan_file"):
                    plan_file = update.data["plan_file"]

        # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        await self.context_store.save(
            session_id=session_id,
            user_message=user_message,
            assistant_response=final_content or "ì‘ë‹µ ì™„ë£Œ",
            analysis=analysis,
            artifacts=artifacts
        )

        # ë‹¤ìŒ í–‰ë™ ì œì•ˆ ìƒì„±
        next_actions = self._suggest_next_actions(
            analysis.get("response_type", ResponseType.QUICK_QA),
            artifacts,
            plan_file
        )

        # ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ìƒì„±
        saved_files = [
            f"âœ“ {a.get('filename')} ({a.get('saved_path', 'ì €ì¥ë¨')})"
            for a in artifacts if a.get("saved")
        ]
        saved_summary = "\n".join(saved_files) if saved_files else "ìƒì„±ëœ íŒŒì¼ ì—†ìŒ"

        # ìµœì¢… ì™„ë£Œ ì—…ë°ì´íŠ¸
        yield StreamUpdate(
            agent="UnifiedAgentManager",
            update_type="done",
            status="completed",
            message="ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            streaming_content=f"## ì‘ì—… ì™„ë£Œ\n\n### ìƒì„±ëœ íŒŒì¼ ({len(artifacts)}ê°œ)\n{saved_summary}",
            data={
                "session_id": session_id,
                "artifact_count": len(artifacts),
                "artifacts": artifacts,
                "next_actions": next_actions,
                "plan_file": plan_file
            }
        )

    async def _save_artifact_to_workspace(
        self,
        artifact: Dict[str, Any],
        workspace: str
    ) -> Dict[str, Any]:
        """Artifactë¥¼ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì €ì¥

        ë™ì¼í•œ íŒŒì¼ì´ ì¡´ì¬í•  ê²½ìš°:
        - ë™ì¼ ë‚´ìš©: ì €ì¥ ê±´ë„ˆë›°ê¸° (skip)
        - ë‹¤ë¥¸ ë‚´ìš©: ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° (modify)

        Args:
            artifact: ì €ì¥í•  artifact ì •ë³´ (filename, content, language)
            workspace: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ

        Returns:
            Dict: ì €ì¥ ê²°ê³¼ (saved, saved_path, saved_at, error, action)
        """
        try:
            filename = artifact.get("filename", "code.py")
            content = artifact.get("content", "")

            if not content:
                return {
                    "saved": False,
                    "saved_path": None,
                    "saved_at": None,
                    "error": "Empty content",
                    "action": None
                }

            # ê²½ë¡œ ì •ë¦¬ (ë³´ì•ˆ: ê²½ë¡œ íƒˆì¶œ ë°©ì§€)
            # íŒŒì¼ëª…ì—ì„œ ìƒìœ„ ë””ë ‰í† ë¦¬ ì´ë™ ë°©ì§€
            safe_parts = []
            for part in filename.replace("\\", "/").split("/"):
                if part and part != ".." and part != ".":
                    safe_parts.append(part)

            if not safe_parts:
                safe_parts = ["code.py"]

            safe_filename = "/".join(safe_parts)
            file_path = Path(workspace) / safe_filename

            # ë¶€ëª¨ ë””ë ‰í† ë¦¬ ìƒì„±
            file_path.parent.mkdir(parents=True, exist_ok=True)

            action = "created"  # ê¸°ë³¸ ì•¡ì…˜

            # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
            if file_path.exists():
                try:
                    # ê¸°ì¡´ íŒŒì¼ ë‚´ìš© ì½ê¸°
                    async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                        existing_content = await f.read()

                    # ë‚´ìš©ì´ ë™ì¼í•˜ë©´ ì €ì¥ ê±´ë„ˆë›°ê¸°
                    if existing_content.strip() == content.strip():
                        logger.info(f"Skipped duplicate artifact: {file_path}")
                        return {
                            "saved": True,
                            "saved_path": str(file_path),
                            "saved_at": datetime.now().isoformat(),
                            "error": None,
                            "action": "skipped_duplicate"
                        }

                    # ë‚´ìš©ì´ ë‹¤ë¥´ë©´ ê¸°ì¡´ íŒŒì¼ ìˆ˜ì • (ë®ì–´ì“°ê¸°)
                    action = "modified"
                    logger.info(f"Modifying existing file: {file_path}")

                except Exception as read_error:
                    logger.warning(f"Could not read existing file for comparison: {read_error}")
                    # ì½ê¸° ì‹¤íŒ¨ ì‹œì—ë„ ë®ì–´ì“°ê¸° ì§„í–‰
                    action = "modified"

            # íŒŒì¼ ì €ì¥
            async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:
                await f.write(content)

            logger.info(f"Saved artifact to: {file_path} (action: {action})")

            return {
                "saved": True,
                "saved_path": str(file_path),
                "saved_at": datetime.now().isoformat(),
                "error": None,
                "action": action
            }

        except Exception as e:
            logger.error(f"Failed to save artifact: {e}")
            return {
                "saved": False,
                "saved_path": None,
                "saved_at": None,
                "error": str(e),
                "action": None
            }

    async def get_context(self, session_id: str) -> ConversationContext:
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ

        Args:
            session_id: ì„¸ì…˜ ID

        Returns:
            ConversationContext: ì»¨í…ìŠ¤íŠ¸ ê°ì²´
        """
        return await self.context_store.load(session_id)

    async def clear_context(self, session_id: str):
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”

        Args:
            session_id: ì„¸ì…˜ ID
        """
        await self.context_store.clear(session_id)
        logger.info(f"Context cleared: {session_id}")

    def get_stats(self) -> Dict[str, Any]:
        """ë§¤ë‹ˆì € í†µê³„ ì¡°íšŒ

        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        return {
            "context_store": self.context_store.get_stats(),
            "handlers": list(self.handlers.keys()),
            "supervisor_model": self.supervisor.model_type
        }

    def _suggest_next_actions(
        self,
        response_type: str,
        artifacts: List[Dict[str, Any]],
        plan_file: Optional[str]
    ) -> List[str]:
        """ì‘ë‹µ íƒ€ì…ê³¼ ê²°ê³¼ì— ë”°ë¥¸ ë‹¤ìŒ í–‰ë™ ì œì•ˆ

        Args:
            response_type: ì‘ë‹µ íƒ€ì…
            artifacts: ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸
            plan_file: ê³„íš íŒŒì¼ ê²½ë¡œ

        Returns:
            List[str]: ì œì•ˆëœ ë‹¤ìŒ í–‰ë™ ëª©ë¡
        """
        actions = []

        if response_type == ResponseType.QUICK_QA:
            actions.append("ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°")

        elif response_type == ResponseType.PLANNING:
            actions.append("ì½”ë“œ ìƒì„± ì‹œì‘")
            actions.append("ê³„íš ìˆ˜ì • ìš”ì²­")
            if plan_file:
                actions.append("ê³„íš íŒŒì¼ í™•ì¸")

        elif response_type == ResponseType.CODE_GENERATION:
            if artifacts:
                actions.append("í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
                actions.append("ì½”ë“œ ë¦¬ë·° ìš”ì²­")
            actions.append("ì¶”ê°€ ê¸°ëŠ¥ êµ¬í˜„")
            actions.append("ì½”ë“œ ìˆ˜ì • ìš”ì²­")

        elif response_type == ResponseType.CODE_REVIEW:
            actions.append("ìˆ˜ì • ì‚¬í•­ ì ìš©")
            actions.append("ì¶”ê°€ ë¦¬ë·° ìš”ì²­")

        elif response_type == ResponseType.DEBUGGING:
            actions.append("ìˆ˜ì • ì‚¬í•­ ì ìš©")
            actions.append("í…ŒìŠ¤íŠ¸ ì‹¤í–‰")

        return actions


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_unified_manager: Optional[UnifiedAgentManager] = None


def get_unified_agent_manager() -> UnifiedAgentManager:
    """UnifiedAgentManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Returns:
        UnifiedAgentManager: í†µí•© ì—ì´ì „íŠ¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
    """
    global _unified_manager
    if _unified_manager is None:
        _unified_manager = UnifiedAgentManager()
    return _unified_manager
