"""Hybrid RAG - ë²¡í„° ê²€ìƒ‰ê³¼ Knowledge Graph í†µí•©

ë²¡í„° ê²€ìƒ‰(ì‹œë§¨í‹±)ê³¼ ê·¸ë˜í”„ íƒìƒ‰(ê´€ê³„)ì„ ê²°í•©í•˜ì—¬
ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""
import re
import logging
from typing import List, Dict, Optional, Tuple, Set
from dataclasses import dataclass, field
from pathlib import Path

from app.services.vector_db import vector_db, SearchResult
from app.services.rag_context import RAGContextBuilder, RAGContext
from app.memory.knowledge_graph import (
    KnowledgeGraph, Concept, Relationship, get_knowledge_graph
)

logger = logging.getLogger(__name__)


@dataclass
class GraphSearchResult:
    """ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼"""
    concept_id: str
    concept_type: str
    name: str
    relationship: str
    depth: int
    properties: Dict = field(default_factory=dict)


@dataclass
class HybridRAGContext:
    """í•˜ì´ë¸Œë¦¬ë“œ RAG ì»¨í…ìŠ¤íŠ¸"""
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
    vector_context: str
    vector_results_count: int
    files_from_vector: List[str]

    # ê·¸ë˜í”„ íƒìƒ‰ ê²°ê³¼
    graph_context: str
    graph_results_count: int
    related_concepts: List[str]

    # ëŒ€í™” ê²€ìƒ‰ ê²°ê³¼
    conversation_context: str
    conversation_results: int

    # ë©”íƒ€ë°ì´í„°
    search_query: str
    avg_relevance: float


class CodeGraphBuilder:
    """ì½”ë“œë² ì´ìŠ¤ì—ì„œ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ëŠ” ë¹Œë”

    íŒŒì¼ ê°„ì˜ ê´€ê³„, import êµ¬ë¬¸, í´ë˜ìŠ¤/í•¨ìˆ˜ ì°¸ì¡° ë“±ì„
    ë¶„ì„í•˜ì—¬ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    """

    # ì§€ì›í•˜ëŠ” import íŒ¨í„´
    PYTHON_IMPORT_PATTERNS = [
        r'^import\s+([\w.]+)',
        r'^from\s+([\w.]+)\s+import',
    ]

    JS_IMPORT_PATTERNS = [
        r'^import\s+.*?\s+from\s+[\'"]([^"\']+)[\'"]',
        r'^const\s+\w+\s*=\s*require\([\'"]([^"\']+)[\'"]\)',
    ]

    def __init__(self, session_id: str, workspace: str):
        """CodeGraphBuilder ì´ˆê¸°í™”

        Args:
            session_id: ì„¸ì…˜ ID
            workspace: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ
        """
        self.session_id = session_id
        self.workspace = Path(workspace)
        self.graph = get_knowledge_graph(session_id)
        self.logger = logging.getLogger(f"{__name__}.{session_id[:8]}")

    def build_from_files(self, file_paths: List[str]) -> int:
        """íŒŒì¼ ëª©ë¡ì—ì„œ ê·¸ë˜í”„ êµ¬ì¶•

        Args:
            file_paths: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ ëª©ë¡

        Returns:
            int: ì¶”ê°€ëœ ë…¸ë“œ ìˆ˜
        """
        nodes_added = 0

        for file_path in file_paths:
            try:
                # íŒŒì¼ ë…¸ë“œ ì¶”ê°€
                file_concept = self._create_file_concept(file_path)
                self.graph.add_concept(file_concept)
                nodes_added += 1

                # íŒŒì¼ ë‚´ìš© ë¶„ì„
                content = Path(file_path).read_text(encoding='utf-8', errors='ignore')
                language = self._detect_language(file_path)

                # Import/ì˜ì¡´ì„± ë¶„ì„
                imports = self._extract_imports(content, language)
                for imp in imports:
                    # ì˜ì¡´ì„± ë…¸ë“œ ì¶”ê°€
                    dep_concept = Concept(
                        id=f"dep:{imp}",
                        type="dependency",
                        name=imp,
                        properties={"source": file_path}
                    )
                    self.graph.add_concept(dep_concept)

                    # ê´€ê³„ ì¶”ê°€
                    rel = Relationship(
                        source_id=file_concept.id,
                        target_id=dep_concept.id,
                        relationship_type="imports",
                        properties={}
                    )
                    self.graph.add_relationship(rel)
                    nodes_added += 1

                # í´ë˜ìŠ¤/í•¨ìˆ˜ ë¶„ì„
                definitions = self._extract_definitions(content, language, file_path)
                for defn in definitions:
                    self.graph.add_concept(defn)
                    # íŒŒì¼ê³¼ì˜ ê´€ê³„
                    rel = Relationship(
                        source_id=file_concept.id,
                        target_id=defn.id,
                        relationship_type="contains",
                        properties={}
                    )
                    self.graph.add_relationship(rel)
                    nodes_added += 1

            except Exception as e:
                self.logger.warning(f"Failed to analyze {file_path}: {e}")

        self.logger.info(f"Built graph: {nodes_added} nodes from {len(file_paths)} files")
        return nodes_added

    def _create_file_concept(self, file_path: str) -> Concept:
        """íŒŒì¼ Concept ìƒì„±"""
        path = Path(file_path)
        try:
            rel_path = path.relative_to(self.workspace)
        except ValueError:
            rel_path = path

        return Concept(
            id=f"file:{rel_path}",
            type="file",
            name=path.name,
            properties={
                "path": str(rel_path),
                "extension": path.suffix,
                "directory": str(rel_path.parent)
            }
        )

    def _detect_language(self, file_path: str) -> str:
        """íŒŒì¼ ì–¸ì–´ ê°ì§€"""
        ext = Path(file_path).suffix.lower()
        lang_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.jsx': 'javascript',
            '.tsx': 'typescript',
        }
        return lang_map.get(ext, 'unknown')

    def _extract_imports(self, content: str, language: str) -> List[str]:
        """Import êµ¬ë¬¸ ì¶”ì¶œ"""
        imports = []

        if language == 'python':
            patterns = self.PYTHON_IMPORT_PATTERNS
        elif language in ('javascript', 'typescript'):
            patterns = self.JS_IMPORT_PATTERNS
        else:
            return imports

        for line in content.split('\n'):
            for pattern in patterns:
                match = re.match(pattern, line.strip())
                if match:
                    imports.append(match.group(1))

        return imports

    def _extract_definitions(
        self, content: str, language: str, file_path: str
    ) -> List[Concept]:
        """í´ë˜ìŠ¤/í•¨ìˆ˜ ì •ì˜ ì¶”ì¶œ"""
        definitions = []

        if language == 'python':
            # í´ë˜ìŠ¤ ì¶”ì¶œ
            for match in re.finditer(r'^class\s+(\w+)', content, re.MULTILINE):
                definitions.append(Concept(
                    id=f"class:{file_path}::{match.group(1)}",
                    type="class",
                    name=match.group(1),
                    properties={"file": file_path}
                ))

            # í•¨ìˆ˜ ì¶”ì¶œ
            for match in re.finditer(r'^def\s+(\w+)', content, re.MULTILINE):
                definitions.append(Concept(
                    id=f"function:{file_path}::{match.group(1)}",
                    type="function",
                    name=match.group(1),
                    properties={"file": file_path}
                ))

        elif language in ('javascript', 'typescript'):
            # í´ë˜ìŠ¤ ì¶”ì¶œ
            for match in re.finditer(r'^(?:export\s+)?class\s+(\w+)', content, re.MULTILINE):
                definitions.append(Concept(
                    id=f"class:{file_path}::{match.group(1)}",
                    type="class",
                    name=match.group(1),
                    properties={"file": file_path}
                ))

            # í•¨ìˆ˜ ì¶”ì¶œ
            for match in re.finditer(r'^(?:export\s+)?(?:async\s+)?function\s+(\w+)', content, re.MULTILINE):
                definitions.append(Concept(
                    id=f"function:{file_path}::{match.group(1)}",
                    type="function",
                    name=match.group(1),
                    properties={"file": file_path}
                ))

        return definitions


class HybridRAGBuilder:
    """í•˜ì´ë¸Œë¦¬ë“œ RAG ë¹Œë”

    ë²¡í„° ê²€ìƒ‰ê³¼ Knowledge Graph íƒìƒ‰ì„ ê²°í•©í•˜ì—¬
    ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, session_id: str, workspace: Optional[str] = None):
        """HybridRAGBuilder ì´ˆê¸°í™”

        Args:
            session_id: ì„¸ì…˜ ID
            workspace: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ (ê·¸ë˜í”„ êµ¬ì¶•ìš©)
        """
        self.session_id = session_id
        self.workspace = workspace
        self.rag_builder = RAGContextBuilder(session_id)
        self.graph = get_knowledge_graph(session_id)
        self.logger = logging.getLogger(f"{__name__}.{session_id[:8]}")

    def build_context(
        self,
        query: str,
        n_vector_results: int = 5,
        n_graph_results: int = 3,
        graph_depth: int = 2,
        min_relevance: float = 0.5,
        include_conversation: bool = True
    ) -> HybridRAGContext:
        """í•˜ì´ë¸Œë¦¬ë“œ RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_vector_results: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            n_graph_results: ê·¸ë˜í”„ íƒìƒ‰ ê²°ê³¼ ìˆ˜
            graph_depth: ê·¸ë˜í”„ íƒìƒ‰ ê¹Šì´
            min_relevance: ìµœì†Œ ê´€ë ¨ì„±
            include_conversation: ëŒ€í™” ê²€ìƒ‰ í¬í•¨ ì—¬ë¶€

        Returns:
            HybridRAGContext: í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸
        """
        # 1. ë²¡í„° ê²€ìƒ‰ (ì½”ë“œ + ëŒ€í™”)
        _, rag_context = self.rag_builder.enrich_query(
            query,
            n_results=n_vector_results,
            min_relevance=min_relevance,
            include_conversation=include_conversation
        )

        # 2. ê·¸ë˜í”„ íƒìƒ‰ (ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‹œì‘)
        graph_results = self._traverse_graph(
            rag_context.files_referenced,
            depth=graph_depth,
            max_results=n_graph_results
        )

        # 3. ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        graph_context, related_concepts = self._format_graph_results(graph_results)

        self.logger.info(
            f"Hybrid RAG: {rag_context.results_count} vector, "
            f"{len(graph_results)} graph, "
            f"{rag_context.conversation_results} conversation"
        )

        return HybridRAGContext(
            vector_context=rag_context.formatted_context,
            vector_results_count=rag_context.results_count,
            files_from_vector=rag_context.files_referenced,
            graph_context=graph_context,
            graph_results_count=len(graph_results),
            related_concepts=related_concepts,
            conversation_context=rag_context.conversation_context,
            conversation_results=rag_context.conversation_results,
            search_query=query,
            avg_relevance=rag_context.avg_relevance
        )

    def _traverse_graph(
        self,
        starting_files: List[str],
        depth: int = 2,
        max_results: int = 5
    ) -> List[GraphSearchResult]:
        """ê·¸ë˜í”„ íƒìƒ‰

        ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ íŒŒì¼ë“¤ì—ì„œ ì‹œì‘í•˜ì—¬
        ê´€ë ¨ëœ ê°œë…ë“¤ì„ íƒìƒ‰í•©ë‹ˆë‹¤.

        Args:
            starting_files: ì‹œì‘ íŒŒì¼ ëª©ë¡
            depth: íƒìƒ‰ ê¹Šì´
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            List[GraphSearchResult]: ê·¸ë˜í”„ íƒìƒ‰ ê²°ê³¼
        """
        results = []
        visited: Set[str] = set()

        for file_ref in starting_files[:3]:  # ìƒìœ„ 3ê°œ íŒŒì¼ë§Œ
            # íŒŒì¼ëª…ì—ì„œ concept ID ì¶”ë¡ 
            file_name = Path(file_ref).name if '::' not in file_ref else file_ref.split('::')[0]

            # ê·¸ë˜í”„ì—ì„œ ê´€ë ¨ íŒŒì¼ ë…¸ë“œ ì°¾ê¸°
            file_nodes = self.graph.search_concepts("file", {"name": file_name})

            for file_node in file_nodes:
                if file_node.id in visited:
                    continue
                visited.add(file_node.id)

                # ê´€ë ¨ ê°œë… íƒìƒ‰
                related = self.graph.get_related_concepts(
                    file_node.id,
                    depth=depth
                )

                for concept in related:
                    if concept.id in visited:
                        continue
                    visited.add(concept.id)

                    # ê´€ê³„ íƒ€ì… ì¶”ì¶œ
                    edge_data = self.graph.graph.get_edge_data(file_node.id, concept.id)
                    rel_type = edge_data.get("type", "related") if edge_data else "related"

                    results.append(GraphSearchResult(
                        concept_id=concept.id,
                        concept_type=concept.type,
                        name=concept.name,
                        relationship=rel_type,
                        depth=1,
                        properties=concept.properties
                    ))

                    if len(results) >= max_results:
                        return results

        return results

    def _format_graph_results(
        self,
        results: List[GraphSearchResult]
    ) -> Tuple[str, List[str]]:
        """ê·¸ë˜í”„ ê²°ê³¼ í¬ë§·íŒ…

        Args:
            results: ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼

        Returns:
            Tuple[str, List[str]]: (í¬ë§·ëœ ì»¨í…ìŠ¤íŠ¸, ê´€ë ¨ ê°œë… ëª©ë¡)
        """
        if not results:
            return "", []

        parts = ["## Related Code (from Knowledge Graph)\n"]
        concepts = []

        for i, result in enumerate(results, 1):
            type_icon = {
                "file": "ğŸ“„",
                "class": "ğŸ“¦",
                "function": "âš¡",
                "dependency": "ğŸ“š"
            }.get(result.concept_type, "ğŸ“Œ")

            parts.append(
                f"### [{i}] {type_icon} {result.name} ({result.concept_type})\n"
                f"- Relationship: {result.relationship}\n"
            )

            if result.properties.get("path"):
                parts.append(f"- Path: {result.properties['path']}\n")

            concepts.append(result.name)

        return "\n".join(parts), concepts

    def enrich_query(
        self,
        user_request: str,
        n_vector_results: int = 5,
        n_graph_results: int = 3,
        include_conversation: bool = True
    ) -> Tuple[str, HybridRAGContext]:
        """ì‚¬ìš©ì ìš”ì²­ì„ í•˜ì´ë¸Œë¦¬ë“œ RAGë¡œ ë³´ê°•

        Args:
            user_request: ì›ë³¸ ì‚¬ìš©ì ìš”ì²­
            n_vector_results: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            n_graph_results: ê·¸ë˜í”„ íƒìƒ‰ ê²°ê³¼ ìˆ˜
            include_conversation: ëŒ€í™” ê²€ìƒ‰ í¬í•¨ ì—¬ë¶€

        Returns:
            Tuple[str, HybridRAGContext]: (ë³´ê°•ëœ ìš”ì²­, í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…ìŠ¤íŠ¸)
        """
        context = self.build_context(
            query=user_request,
            n_vector_results=n_vector_results,
            n_graph_results=n_graph_results,
            include_conversation=include_conversation
        )

        # ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        context_parts = []

        if context.vector_context:
            context_parts.append(context.vector_context)

        if context.graph_context:
            context_parts.append(context.graph_context)

        if context.conversation_context:
            context_parts.append(context.conversation_context)

        if context_parts:
            combined = "\n\n".join(context_parts)
            enriched = f"{user_request}\n\n{combined}"
            return enriched, context

        return user_request, context


# ìºì‹œëœ ë¹Œë” ì¸ìŠ¤í„´ìŠ¤
_hybrid_builders: Dict[str, HybridRAGBuilder] = {}


def get_hybrid_rag_builder(
    session_id: str,
    workspace: Optional[str] = None
) -> HybridRAGBuilder:
    """HybridRAGBuilder ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ìºì‹œë¨)

    Args:
        session_id: ì„¸ì…˜ ID
        workspace: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ

    Returns:
        HybridRAGBuilder: ë¹Œë” ì¸ìŠ¤í„´ìŠ¤
    """
    key = f"{session_id}:{workspace or 'default'}"
    if key not in _hybrid_builders:
        _hybrid_builders[key] = HybridRAGBuilder(session_id, workspace)
    return _hybrid_builders[key]
