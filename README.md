# Coding Agent - Full Stack AI Assistant

Claude Code / OpenAI Codex λ°©μ‹μ **Unified Workflow Architecture**λ¥Ό κµ¬ν„ν• AI μ½”λ”© μ–΄μ‹μ¤ν„΄νΈμ…λ‹λ‹¤.

## π—οΈ Architecture

```
User Prompt
    β”‚
    β–Ό
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    Unified Chat Endpoint                         β”‚
β”‚                    POST /chat/unified                            β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
    β”‚
    β–Ό
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    UnifiedAgentManager                           β”‚
β”‚  - μ„Έμ… μ»¨ν…μ¤νΈ κ΄€λ¦¬                                              β”‚
β”‚  - Supervisor λ¶„μ„ μ”μ²­                                           β”‚
β”‚  - μ‘λ‹µ νƒ€μ…λ³„ λΌμ°ν…                                             β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
    β”‚
    β–Ό
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    SupervisorAgent                               β”‚
β”‚  - μ”μ²­ λ¶„μ„ (Reasoning LLM)                                     β”‚
β”‚  - response_type κ²°μ •                                            β”‚
β”‚  - λ³µμ΅λ„ ν‰κ°€                                                    β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
    β”‚
    β”β”€β–Ί QUICK_QA β”€β”€β”€β”€β”€β”€β”€β”€β”€β–Ί Direct LLM Response
    β”β”€β–Ί PLANNING β”€β”€β”€β”€β”€β”€β”€β”€β”€β–Ί PlanningHandler (κ³„ν μƒμ„± + νμΌ μ €μ¥)
    β”β”€β–Ί CODE_GENERATION β”€β”€β–Ί CodeGenerationHandler (μ›ν¬ν”λ΅μ° μ‹¤ν–‰)
    β”β”€β–Ί CODE_REVIEW β”€β”€β”€β”€β”€β”€β–Ί CodeReviewHandler
    β””β”€β–Ί DEBUGGING β”€β”€β”€β”€β”€β”€β”€β”€β–Ί DebuggingHandler
    β”‚
    β–Ό
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    ResponseAggregator                            β”‚
β”‚  - UnifiedResponse μƒμ„±                                          β”‚
β”‚  - Next Actions μ μ•                                             β”‚
β”‚  - μ»¨ν…μ¤νΈ DB μ €μ¥                                               β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

## π“‹ Features

### Unified Workflow Architecture
- **λ‹¨μΌ μ§„μ…μ **: λ¨λ“  μ”μ²­μ΄ Supervisorλ¥Ό ν†µκ³Ό
- **μ§€λ¥μ  λΌμ°ν…**: μ”μ²­ μ ν•μ— λ”°λ¥Έ μλ™ κ²½λ΅ κ²°μ • (QUICK_QA, PLANNING, CODE_GENERATION λ“±)
- **ν†µν•© μ‘λ‹µ ν¬λ§·**: λ¨λ“  κ²½λ΅μ—μ„ λ™μΌν• μ‘λ‹µ κµ¬μ΅°
- **μ»¨ν…μ¤νΈ μμ†μ„±**: λ€ν™” λ° μ‘μ—… μ»¨ν…μ¤νΈ DB μ €μ¥
- **Next Actions UI**: μ‘λ‹µ νƒ€μ…λ³„ λ§μ¶¤ν• λ‹¤μ ν–‰λ™ μ μ•

### LLM Provider Abstraction
- **λ‹¤μ¤‘ λ¨λΈ μ§€μ›**: DeepSeek-R1, Qwen3-Coder, GPT-OSS
- **λ¨λΈλ³„ μ–΄λ‘ν„°**: μλ™ ν”„λ΅¬ν”„νΈ μµμ ν™”
- **ν•κµ­μ–΄ μ§€μ›**: λ™μ‚¬ μ–΄κ°„ κΈ°λ° ν¨ν„΄ λ§¤μΉ­

### User Interface
- **Claude.ai μ¤νƒ€μΌ**: κΉ”λ”ν• λ€ν™”ν• μΈν„°νμ΄μ¤
- **μ‹¤μ‹κ°„ μ¤νΈλ¦¬λ°**: μ½”λ“ μƒμ„± κ³Όμ • μ‹¤μ‹κ°„ ν‘μ‹
- **κ³„ν νμΌ λ·°μ–΄**: λ³µμ΅ν• μ‘μ—… κ³„ν λ―Έλ¦¬λ³΄κΈ°
- **λ°μ‘ν• λ””μμΈ**: λ°μ¤ν¬ν†±/λ¨λ°”μΌ μ§€μ›

## π€ Quick Start

### Prerequisites

1. **vLLM μ„λ²„** (μ•± μ‹μ‘ μ „ μ‹¤ν–‰ ν•„μ”):
   ```bash
   # Terminal 1: Reasoning Model
   vllm serve deepseek-ai/DeepSeek-R1 --port 8001

   # Terminal 2: Coding Model
   vllm serve Qwen/Qwen3-8B-Coder --port 8002
   ```

2. **Python 3.12** and **Node.js 20+**

### Development Setup

```bash
# 1. ν™κ²½ μ„¤μ •
cp .env.example .env
# .env νμΌμ—μ„ μ„¤μ •:
#   - LLM μ—”λ“ν¬μΈνΈ (VLLM_REASONING_ENDPOINT, VLLM_CODING_ENDPOINT)
#   - Workspace λ””λ ‰ν† λ¦¬ (DEFAULT_WORKSPACE)
#
# μμ‹:
# DEFAULT_WORKSPACE=/home/username/Workspaces/TestCode
# β†’ ν”„λ΅μ νΈλ” /home/username/Workspaces/TestCode/{session_id}/{project_name}μ— μ €μ¥λ©λ‹λ‹¤

# 2. Backend
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# 3. Frontend
cd frontend
npm install
npm run dev
```

Frontend: http://localhost:5173

### Mock Mode (vLLM μ—†μ΄ ν…μ¤νΈ)

```bash
./RUN_MOCK.sh  # λλ” Windows: RUN_MOCK.bat
```

## π“ Project Structure

```
TestCodeAgent/
β”β”€β”€ backend/
β”‚   β”β”€β”€ app/
β”‚   β”‚   β”β”€β”€ main.py                         # FastAPI entry point
β”‚   β”‚   β”β”€β”€ agent/
β”‚   β”‚   β”‚   β”β”€β”€ unified_agent_manager.py    # ν†µν•© μ—μ΄μ „νΈ λ§¤λ‹μ €
β”‚   β”‚   β”‚   β””β”€β”€ handlers/                   # μ‘λ‹µ νƒ€μ…λ³„ ν•Έλ“¤λ¬
β”‚   β”‚   β””β”€β”€ api/
β”‚   β”‚       β””β”€β”€ main_routes.py              # /chat/unified μ—”λ“ν¬μΈνΈ
β”‚   β”β”€β”€ core/
β”‚   β”‚   β”β”€β”€ supervisor.py                   # SupervisorAgent
β”‚   β”‚   β”β”€β”€ response_aggregator.py          # UnifiedResponse
β”‚   β”‚   β””β”€β”€ context_store.py                # μ»¨ν…μ¤νΈ μ €μ¥μ†
β”‚   β””β”€β”€ shared/
β”‚       β””β”€β”€ llm/
β”‚           β”β”€β”€ base.py                     # LLMProvider μΈν„°νμ΄μ¤
β”‚           β””β”€β”€ adapters/                   # λ¨λΈλ³„ μ–΄λ‘ν„°
β”β”€β”€ frontend/
β”‚   β””β”€β”€ src/
β”‚       β”β”€β”€ components/
β”‚       β”‚   β”β”€β”€ WorkflowInterface.tsx       # Unified λ¨λ“ UI
β”‚       β”‚   β”β”€β”€ NextActionsPanel.tsx        # λ‹¤μ ν–‰λ™ λ²„νΌ
β”‚       β”‚   β””β”€β”€ PlanFileViewer.tsx          # κ³„ν νμΌ λ·°μ–΄
β”‚       β””β”€β”€ api/
β”‚           β””β”€β”€ client.ts                   # API ν΄λΌμ΄μ–ΈνΈ
β””β”€β”€ docs/                                   # κΈ°μ  λ¬Έμ„
```

## π― API Endpoints

### Unified Chat (Non-streaming)
```
POST /chat/unified
```

```json
// Request
{
  "message": "PythonμΌλ΅ κ³„μ‚°κΈ° λ§λ“¤μ–΄μ¤",
  "session_id": "session-123",
  "workspace": "/home/user/workspace"
}

// Response
{
  "response_type": "code_generation",
  "content": "## μ½”λ“ μƒμ„± μ™„λ£\n\n...",
  "artifacts": [...],
  "next_actions": ["ν…μ¤νΈ μ‹¤ν–‰", "μ½”λ“ λ¦¬λ·° μ”μ²­"],
  "session_id": "session-123",
  "success": true
}
```

### Unified Chat (Streaming)
```
POST /chat/unified/stream
```

## π”§ Configuration

### Environment Variables

```env
# Primary LLM
LLM_ENDPOINT=http://localhost:8001/v1
LLM_MODEL=deepseek-ai/DeepSeek-R1
MODEL_TYPE=deepseek  # deepseek, qwen, gpt-oss, generic

# Optional: Task-specific endpoints
VLLM_REASONING_ENDPOINT=http://localhost:8001/v1
VLLM_CODING_ENDPOINT=http://localhost:8002/v1
REASONING_MODEL=deepseek-ai/DeepSeek-R1
CODING_MODEL=Qwen/Qwen3-8B-Coder

# Server
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
```

## π“ Documentation

| λ¬Έμ„ | μ„¤λ… |
|------|------|
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | μ‹μ¤ν… μ•„ν‚¤ν…μ² μƒμ„Έ |
| [MOCK_MODE.md](docs/MOCK_MODE.md) | Mock λ¨λ“ ν…μ¤νΈ κ°€μ΄λ“ |
| [MULTI_USER_ANALYSIS.md](docs/MULTI_USER_ANALYSIS.md) | λ‹¤μ¤‘ μ‚¬μ©μ λ™μ‹ μ ‘μ† λ¶„μ„ |
| [OPTIMIZATION_RECOMMENDATIONS.md](docs/OPTIMIZATION_RECOMMENDATIONS.md) | H100 GPU μµμ ν™” κ¶μ¥μ‚¬ν•­ |
| [REFINEMENT_CYCLE_GUIDE.md](docs/REFINEMENT_CYCLE_GUIDE.md) | μ½”λ“ κ°μ„  μ›ν¬ν”λ΅μ° κ°€μ΄λ“ |
| [INSTALL_CONDA.md](INSTALL_CONDA.md) | Conda ν™κ²½ μ„¤μΉ κ°€μ΄λ“ |

### Archive (μ™„λ£λ μ‘μ—… λ¬Έμ„)
| λ¬Έμ„ | μ„¤λ… |
|------|------|
| [LLM_MODEL_CHANGE_PLAN.md](docs/archive/LLM_MODEL_CHANGE_PLAN.md) | LLM μ¶”μƒν™” κ³„μΈµ κµ¬ν„ μ™„λ£ |
| [AGENT_COMPATIBILITY_AUDIT.md](docs/archive/AGENT_COMPATIBILITY_AUDIT.md) | ν”„λ΅¬ν”„νΈ νΈν™μ„± κ°μ‚¬ μ™„λ£ |
| [IMPROVEMENT_PLAN.md](docs/archive/IMPROVEMENT_PLAN.md) | μ‹μ¤ν… κ°μ„  Phase 1&2 μ™„λ£ |
| [AGENT_EXPANSION_PROPOSAL.md](docs/archive/AGENT_EXPANSION_PROPOSAL.md) | μ—μ΄μ „νΈ ν™•μ¥ μ μ•μ„ |

## π¨ UI Design

Claude.ai μ¤νƒ€μΌ λ””μμΈ:

| Element | Color |
|---------|-------|
| Background | `#FAF9F7` (warm off-white) |
| Accent | `#DA7756` (terracotta) |
| Text Primary | `#1A1A1A` |
| Text Secondary | `#666666` |

## π› οΈ Supported LLM Models

| λ¨λΈ | νΉμ§• | ν”„λ΅¬ν”„νΈ ν•μ‹ |
|------|------|---------------|
| DeepSeek-R1 | μ¶”λ΅  λ¨λΈ | `<think></think>` νƒκ·Έ |
| Qwen3-Coder | μ½”λ”© νΉν™” | Standard prompts |
| GPT-OSS | OpenAI Harmony | Structured reasoning |

## π“„ License

MIT License - see LICENSE file for details
