# ============================================
# AI Code Assistance Application Configuration
# ============================================
# Copy this file to .env and modify as needed
# cp .env.example .env

# =========================
# LLM Configuration
# =========================

# Primary LLM endpoint (used as default for all tasks)
# IMPORTANT: Use localhost or 127.0.0.1, NOT 0.0.0.0 for client connections
LLM_ENDPOINT=http://localhost:8001/v1
LLM_MODEL=deepseek-ai/DeepSeek-R1

# Model type override (OPTIONAL - auto-detected from model name)
# The system automatically detects model type from model names:
#   - "deepseek" in name → deepseek prompts (<think> tags)
#   - "qwen" in name → qwen prompts
#   - "gpt-oss" in name → gpt-oss prompts (Harmony format, reasoning effort)
#   - "gpt/openai" in name → gpt prompts
#   - "claude/anthropic" in name → claude prompts
#   - others → generic prompts
# Only set this if you need to override auto-detection
# MODEL_TYPE=deepseek

# Task-specific endpoints (override LLM_ENDPOINT for specific tasks)
VLLM_REASONING_ENDPOINT=http://localhost:8001/v1
VLLM_CODING_ENDPOINT=http://localhost:8002/v1

# Task-specific models (auto-detected model type for each)
# Example: DeepSeek for reasoning, Qwen for coding
REASONING_MODEL=deepseek-ai/DeepSeek-R1
CODING_MODEL=Qwen/Qwen3-8B-Coder

# Task-specific model type overrides (OPTIONAL)
# Use when you need different adapters per task
# REASONING_MODEL_TYPE=gpt-oss
# CODING_MODEL_TYPE=gpt-oss

# =========================
# GPT-OSS Configuration (OpenAI's Open-Source Model)
# =========================
# For using GPT-OSS-120B for both reasoning and coding:
# VLLM_REASONING_ENDPOINT=http://localhost:8001/v1
# VLLM_CODING_ENDPOINT=http://localhost:8002/v1
# REASONING_MODEL=openai/gpt-oss-120b
# CODING_MODEL=openai/gpt-oss-120b
#
# Reasoning effort level: low (default, fast), medium (balanced), high (thorough)
GPT_OSS_REASONING_EFFORT=low

# =========================
# Agent Framework Selection
# =========================
# Options: microsoft, langchain, deepagent
# - microsoft: Original Microsoft Agent Framework (default)
# - langchain: LangChain/LangGraph based agents
# - deepagent: DeepAgents with advanced capabilities
AGENT_FRAMEWORK=microsoft

# =========================
# Workflow Configuration
# =========================
# Maximum code review/refinement iterations
# Lower values = faster execution, higher values = better quality
# Recommended:
#   1 = Fast (no refinement, use first generated code)
#   2 = Balanced (1 review + 1 fix if needed)
#   3 = Quality (up to 3 review/fix cycles)
# Note: Each iteration adds ~30-60 seconds
MAX_REVIEW_ITERATIONS=1

# =========================
# API Server Configuration
# =========================
# Note: 0.0.0.0 is correct here for SERVER binding (accepts all interfaces)
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# =========================
# CORS Configuration
# =========================
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# =========================
# Workspace Configuration
# =========================
# Default workspace directory where all projects will be stored
# Structure: DEFAULT_WORKSPACE/{session_id}/{project_name}
# Example: /home/username/Workspaces/TestCode/session-abc123/calculator
#
# If not set, defaults to: {user_home}/workspace
# Linux/Mac: /home/username/workspace
# Windows: C:\Users\username\workspace
DEFAULT_WORKSPACE=/home/username/Workspaces/TestCode

# =========================
# Logging
# =========================
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =========================
# Network Mode Configuration (Phase 2)
# =========================
# Controls which tools are available based on network access
# Options:
#   - online  : All tools available (default, requires internet for web search)
#   - offline : Only local tools (no external network requests)
#
# Security Policy:
#   - EXTERNAL_API tools (Tavily search, REST APIs) blocked in offline mode
#   - EXTERNAL_DOWNLOAD tools (wget/curl) allowed in offline mode
#   - LOCAL tools (file, code, git) always available
#
# Use 'offline' in secure/air-gapped networks
NETWORK_MODE=online

# =========================
# Agent Tools Configuration
# =========================
# Tavily API Key for Web Search Tool (ONLINE MODE ONLY)
# Get your API key at: https://tavily.com
# Leave empty to disable web search functionality
# Note: Ignored in offline mode
TAVILY_API_KEY=

# ChromaDB Path for Code Search Tool (WORKS OFFLINE)
# Default: ./chroma_db (relative to project root)
CHROMA_DB_PATH=./chroma_db

# =========================
# Sandbox Configuration (Phase 4)
# =========================
# AIO Sandbox for isolated code execution
# Docker container-based secure execution environment

# Docker image for sandbox (default: AIO Sandbox from GitHub Container Registry)
# For offline/airgapped environments, use your internal registry:
#   SANDBOX_IMAGE=harbor.company.com/sandbox/aio:latest
SANDBOX_IMAGE=ghcr.io/agent-infra/sandbox:latest

# Internal registry for offline environments (optional)
# When set, overrides SANDBOX_IMAGE to use: {registry}/sandbox/aio:latest
# SANDBOX_REGISTRY=harbor.company.com

# Sandbox API settings
SANDBOX_HOST=localhost
SANDBOX_PORT=8080

# Execution limits
SANDBOX_TIMEOUT=60
SANDBOX_MEMORY=1g
SANDBOX_CPU=2.0
